+++
title = "Trees"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Data Structures]({{< relref "20230403192236-data_structures.md" >}}), [Graphs]({{< relref "20230521010631-graphs.md" >}})


## Tree Traversal {#tree-traversal}


### Meta ideas about tree traversal {#meta-ideas-about-tree-traversal}

-   We usually just go L -&gt; R


#### Complexity {#complexity}

-   All trees have `n - 1` edges, `n` being the number of nodes.
-   Time complexity: `O(V + E)` &rArr; \\(O(n + (n-1)) = O(n)\\)


#### About {in,pre,post}order {#about-in-pre-post-order}

-   BFS doesn't have `{in,pre,post}order`, those are DFS specific.
-   `{pre,post}order` work for `n-ary` trees, while [inorder becomes a little weird](https://stackoverflow.com/questions/66980517/tree-traversal-pre-and-postorder-for-general-trees-inorder-only-for-binary-tr) for anything that's not a binary tree.


#### Recursion and traversal {#recursion-and-traversal}

|           | BFS (Queue)         | DFS (Stack)                                     |
|-----------|---------------------|-------------------------------------------------|
| Recursive | Not natural         | Yes, that's the way. Preserves shape/structure. |
| Iterative | Yes, that's the way | Unsual to do, might help w limited call stack   |

-   See [Recursive process vs Recursive procedure]({{< relref "20230429205506-recursion.md" >}})


### DFS (Stack) {#dfs--stack}

![](/ox-hugo/20230205172402-algorithms-1202411924.png)
![](/ox-hugo/20230929065117-trees-328537490.png)

-   **Workhorse:** push and pop things on a `stack` (call stack)


#### Preorder {#preorder}

-   `VisitNode() + RecurseL() + RecurseR()`
-   Root's in the beginning


#### Inorder {#inorder}

-   `RecurseL() + VisitNode() + RecurseR()`
-   Root's in the middle
-   Inorder traversal of a Binary search tree will print things in order


#### Postorder {#postorder}

-   `RecurseL() + RecurseR() + VisitNode()`
-   Root's in the end


#### Implementation {#implementation}

-   Recursive
    -   DFS uses a stack to maintain a frontier, and recursion has an implicit stack (call stack)
    -   Implementing DFS using recursion simply means replacing the stack with a call stack.
-   Iterative
    -   To convert it into an iterative DFS you can simply use an actual stack data structure, but you now need to manage the stack yourself.


### BFS (Queue) {#bfs--queue}

{{< figure src="/ox-hugo/20230205172402-algorithms-1385823146.png" >}}

-   **Workhorse:** enqueue and dequeue things on a `queue` (auxiliary storage)

<!--listend-->

```text
while !q.empty?
  curr = q.rm_from_start() // dequeue
  print(curr) // do whatever w curr
  q.enqueue(curr.l)
  q.enqueue(curr.r)
```


#### Implementation {#implementation}

-   Mostly uses a queue
-   BFS and [recursion cannot be combined](https://codeforces.com/blog/entry/18642) as naturally since BFS does not use a stack


## Tree based Structures {#tree-based-structures}


### Basic definitions {#basic-definitions}

-   Root: the most parent node. The First. Adam.
-   Height: The longest path from the root to the most child node
-   Leaves: a node without children
-   Branching factor: the amount of children a tree has
-   General tree: A tree with 0 or more children
-   Binary tree
    -   A tree in which has at most 2 children, at least 0 children
    -   Each level in a binary tree is approx. half the size of the entire tree above it.


### Tree ADTs {#tree-adts}


#### Binary search tree (BST) {#binary-search-tree--bst}

{{< figure src="/ox-hugo/20230403192236-data_structures-1245268333.png" >}}

-   Rule at every node: Left &le; Node &lt; Right (Similar to Quicksort)
-   A tree in which has a specific ordering to the nodes and at most 2 children
-   In-order traversal will result in an ordered list

<!--list-separator-->

-  Search

    -   Searching: Searching is similar to Binary search
    -   Time Complexity: \\(O(log(n))\\) - \\(O(n)\\). \\(O(n)\\) in the case where the BST is simply a linked list. i.e How **balanced** your BST will determine the complexity.

<!--list-separator-->

-  Insertion

    -   Insertion inherently un-balances the tree

<!--list-separator-->

-  Deletion

    -   Choose `smallest on large-side` or `largest on small-side`.
        -   We can choose any but if we have the `individual height` of the node, we can make a better decision as we'll know which one to choose and shrink our tree.
    -   Then replace the parent to be removed with it.


#### Heap/Priority Queue {#heap-priority-queue}

-   Heap is an implementation of a Priority Queue ADT
-   There's usually no need to traversing the tree as you only look at the top for priority
-   A `binary tree` w constraints:
    -   Every child and grand child is smaller (MaxHeap) than current node
    -   Every child and grand child is larger (MinHeap) than current node
    -   i.e Root node is at some extreme
-   Self balancing
    -   Every level of the tree is complete
    -   Whenever a node is added, we must adjust the tree
    -   Whenever a node is deleted, we must adjust the tree

<!--list-separator-->

-  Array Implementation

    {{< figure src="/ox-hugo/20230403192236-data_structures-906634527.png" >}}

<!--list-separator-->

-  Heap-ordered binary tree Implementation

<!--list-separator-->

-  Binary Heap

    -   Binary heaps are a common way of implementing priority queues
    -   The [Data Structures]({{< relref "20230403192236-data_structures.md" >}}) used for `Heapsort`


#### Tries/Prefix Tree/Re'trie'val tree {#tries-prefix-tree-re-trie-val-tree}

-   Used for auto-completion/caching type stuff
-   Value is usually a string

<!--list-separator-->

-  Complexity

    -   You need to think about what `n` is.
    -   The complexity of creating a trie is O(W\*L), where W is the number of words, and L is an average length of the word: you need to perform L lookups on the average for each of the W words in the set.
    -   Same goes for looking up words later: you perform L steps for each of the W words.
        -   If the longest english letter is 12, then it's 12 node check. That's constant time.
        -   In this case `n` is the height and the height is bound by the en dictionary.
        -   So trie is good for cases where you can determine the height in advance


#### Balanced tree {#balanced-tree}

-   Depth is uniform across the entire tree.
-   perfectly balanced when any node‚Äôs left and right children have the same height.
-   There are different ways to balance a tree. Popular rotation techniques are AVL and RB trees.
    -   RB : If I don't find things often but I insert a lot. (Fast balancing)
    -   AVL: If I find a lot but insert rarely. (Slower balancing)


#### Skip List {#skip-list}


#### B-tree / Btree {#b-tree-btree}

{{< figure src="/ox-hugo/20230929065117-trees-2081371836.png" >}}

-   [B-Trees and Database Indexes | Hacker News](https://news.ycombinator.com/item?id=41489832) üåü
-   [Binary Search Tree(BST) vs B-tree](https://www.reddit.com/r/compsci/comments/m7wb6l/what_are_the_important_types_of_tree_data/)
-   [Relational database on top of key-value store explained (or why B-trees are cool) - Gregory Trubetskoy](https://grisha.org/blog/2013/05/11/relational-database-on-top-of-key-value-store-explained/)
-   [The Taming of the B-Trees - ScyllaDB](https://www.scylladb.com/2021/11/23/the-taming-of-the-b-trees/)
-   It's a data structure that aims for ‚Äúread and write large blocks of data‚Äù,
-   Key point is that such trees usually grow wide and shallow, so for some type of query (remember, it‚Äôs still a search tree) only very few nodes are to be ‚Äútouched‚Äù.
    -   This is important, because such access could be very expensive (think of rotating HDD).


#### B+ tree {#b-plus-tree}

-   [The subtleties of proper B+Tree implementation | Hacker News](https://news.ycombinator.com/item?id=38594139)
-   B+tree is a variant on B-Tree
    -   The main difference B+ Trees show off is that intermediate nodes don't store any data on them. Instead, all the data references are linked to the leaf nodes, which allows for better caching of the tree structure.
    -   Secondly, the leaf nodes are linked, so if you need to do an index scan, you can do a single linear pass rather than traversing the entire tree up and down and loading more index data from the disk.


#### LSM Tree / LSMT {#lsm-tree-lsmt}

<!--list-separator-->

-  LSMT in [Database]({{< relref "20221102123145-database.md" >}})

    -   [The Log-Structured Merge-Tree (LSM Tree) | the morning paper](https://blog.acolyer.org/2014/11/26/the-log-structured-merge-tree-lsm-tree/)
    -   [Intro into database storage engines](https://sergeiturukin.com/2017/06/07/storage-engine-introduction.html)
    -   LSM tree normally has an in-memory sorted list of key-value pairs called a [MemTable](https://github.com/facebook/rocksdb/wiki/MemTable). Writes are inserted into this MemTable. To keep writes durable, writes are also sent to a write-ahead log (WAL). When MemTables get large, they‚Äôre frozen (made immutable) and flushed to disk as [sorted-string tables (SSTs)](https://www.scylladb.com/glossary/sstable/). (from materializedview blog)
    -   Allows different storage(write) and access(read) characteristics.
