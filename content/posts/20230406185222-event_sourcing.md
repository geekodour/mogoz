+++
title = "Event Sourcing"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Message Passing]({{< relref "20230404153903-message_passing.md" >}}), [Design Patterns]({{< relref "20221125204047-design_patterns.md" >}})


## FAQ {#faq}


### Streaming vs Processing {#streaming-vs-processing}

These terms are vague, on top of that redpands, pulsar etc. mix these together

-   `Event streaming`: `Storage` and `movement` of data in real time
-   `Event processing`: `Processing` and `connectivity` of data. connecting source &amp; destination.
-   Eg. kafka ecosystem
    -   `Storage and movement`: [Kafka]({{< relref "20230210012126-kafka.md" >}}) broker
    -   `Connectivity`: kafka connect, flink also can do
    -   `Processing`: ksqldb, flink, kstream


## What Models {#what-models}

Model to think about data at rest and data in motion about real world systems.


### State based {#state-based}

-   **Source of truth: A table that can be mutated**
-   This is the more traditional model.
-   More live a snapshot in time

{{< figure src="/ox-hugo/20230406185222-event_sourcing-851778177.png" >}}


### Events based {#events-based}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1970057022.png" >}}

-   **Source of truth: Event log**
-   Storing your data as events
-   Retains more data than state based system
-   Events are immutable (You can't change the past)
-   Event sourcing, Event Streaming, CQRS etc.
-   Current view

    -   Whole stream of events is required to derive the current position

    ![](/ox-hugo/20230406185222-event_sourcing-2005943839.png)
    ![](/ox-hugo/20230406185222-event_sourcing-40528408.png)


#### Advantage {#advantage}

-   Immutability
-   Recoverability: If we discover a bug in our system, once we fix the bug, fixing the data is simply replaying the event stream from that previous point.


#### Disadvantage {#disadvantage}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1643627915.png" >}}

-   Event log can now contain many different versions of the same schema


## Event Sourcing w CQRS {#event-sourcing-w-cqrs}

-   Command Query Responsibility Segregation
-   At its heart is the notion that you can use a different model to update information than the model you use to read information.
-   CQRS is not the only way to do this, but most probably one of the most common ways


### Writing {#writing}

We write to append only log as events happen


### Reading / CQRS {#reading-cqrs}

-   Usually to read from a event log, you'll need to do a **chronological reduce** over the data. This can take a lot of time based on the size of the data.
-   Solution is to compute this at write time(async).

-   Because of this, system becomes **Eventually consistent** ðŸŒŸ
    -   Reads might not be immediately available after write.


## CDC {#cdc}

See [CDC ( Change Data Capture )]({{< relref "20240901210923-cdc_change_data_capture.md" >}})


## Event Streaming {#event-streaming}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1203157960.png" >}}


## Resources {#resources}

-   [Don't Let the Internet Dupe You, Event Sourcing is Hard - Blogomatano](https://chriskiehl.com/article/event-sourcing-is-hard)
-   [Slowly Changing Dimensions - Kimball Group](https://www.kimballgroup.com/2008/08/slowly-changing-dimensions/)
-   [Slowly Changing Dimensions, Part 2 - Kimball Group](https://www.kimballgroup.com/2008/09/slowly-changing-dimensions-part-2/)
-   [Fact Tables - Kimball Group](https://www.kimballgroup.com/2008/11/fact-tables/)
