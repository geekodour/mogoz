+++
title = "Event Sourcing"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Message Passing]({{< relref "20230404153903-message_passing.md" >}}), [Design Patterns]({{< relref "20221125204047-design_patterns.md" >}})


## FAQ {#faq}


### Streaming vs Processing {#streaming-vs-processing}

These terms are vague, on top of that redpands, pulsar etc. mix these together

-   `Event streaming`: `Storage` and `movement` of data in real time
-   `Event processing`: `Processing` and `connectivity` of data. connecting source &amp; destination.
-   Eg. kafka ecosystem
    -   `Storage and movement`: [Kafka]({{< relref "20230210012126-kafka.md" >}}) broker
    -   `Connectivity`: kafka connect, flink also can do
    -   `Processing`: ksqldb, flink, kstream


## What Models {#what-models}

Model to think about data at rest and data in motion about real world systems.


### State based {#state-based}

-   **Source of truth: A table that can be mutated**
-   This is the more traditional model.
-   More live a snapshot in time

{{< figure src="/ox-hugo/20230406185222-event_sourcing-851778177.png" >}}


### Events based {#events-based}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1970057022.png" >}}

-   **Source of truth: Event log**
-   Storing your data as events
-   Retains more data than state based system
-   Events are immutable (You can't change the past)
-   Event sourcing, Event Streaming, CQRS etc.
-   Current view

    -   Whole stream of events is required to derive the current position

    ![](/ox-hugo/20230406185222-event_sourcing-2005943839.png)
    ![](/ox-hugo/20230406185222-event_sourcing-40528408.png)


#### Advantage {#advantage}

-   Immutability
-   Recoverability: If we discover a bug in our system, once we fix the bug, fixing the data is simply replaying the event stream from that previous point.


#### Disadvantage {#disadvantage}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1643627915.png" >}}

-   Event log can now contain many different versions of the same schema


## Event Sourcing w CQRS {#event-sourcing-w-cqrs}

-   Command Query Responsibility Segregation
-   At its heart is the notion that you can use a different model to update information than the model you use to read information.
-   CQRS is not the only way to do this, but most probably one of the most common ways


### Writing {#writing}

We write to append only log as events happen


### Reading / CQRS {#reading-cqrs}

-   Usually to read from a event log, you'll need to do a **chronological reduce** over the data. This can take a lot of time based on the size of the data.
-   Solution is to compute this at write time(async).

-   Because of this, system becomes **Eventually consistent** ðŸŒŸ
    -   Reads might not be immediately available after write.


## CDC {#cdc}

-   If you need to maintain constraints before events are written (e.g. not selling more items than you have in stock). It's easier to use a DB and CDC.
-   CDC enables real-time or near-real-time data synchronization and helps ensure that downstream systems are kept up to date with the latest changes in the data sources.
-   See ["Change Data Capture Breaks Encapsulation". Does it, though?](https://lobste.rs/s/yepcsr/change_data_capture_breaks)


### Outbox Pattern {#outbox-pattern}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-978549675.png" >}}


### CDC vs CQRS {#cdc-vs-cqrs}

-   These are different things and can compliment each other
-   CQRS
    -   Gives us a better and optimized system for r/w if the scenario is right
    -   A pattern that separates the read and write responsibilities of a system into distinct components. CQRS allows for a more optimized and scalable system by tailoring the data models and operations to the specific needs of reading and writing.
-   CDC
    -   Because w Event driven systems, we get eventual consistency, read data might not be upto-date. If we really need it, we can use CDC.
    -   A technique used to capture and propagate data changes from a source system to other systems or components.
    -   It focuses on capturing the changes made to a data source and making those changes available to other parts of the system in a real-time or near-real-time manner.
    -   Can also be used to add constratints before write.


### Replication for CDC {#replication-for-cdc}

See [Data Replication]({{< relref "20231021151742-data_replication.md" >}})
![](/ox-hugo/20230406185222-event_sourcing-1535234753.png)


## Event Streaming {#event-streaming}

{{< figure src="/ox-hugo/20230406185222-event_sourcing-1203157960.png" >}}


## Resources {#resources}

-   [Don't Let the Internet Dupe You, Event Sourcing is Hard - Blogomatano](https://chriskiehl.com/article/event-sourcing-is-hard)
-   [Slowly Changing Dimensions - Kimball Group](https://www.kimballgroup.com/2008/08/slowly-changing-dimensions/)
-   [Slowly Changing Dimensions, Part 2 - Kimball Group](https://www.kimballgroup.com/2008/09/slowly-changing-dimensions-part-2/)
-   [Fact Tables - Kimball Group](https://www.kimballgroup.com/2008/11/fact-tables/)
