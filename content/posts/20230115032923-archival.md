+++
title = "Archival"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Storage]({{< relref "20221101164723-storage.md" >}}), [Scraping]({{< relref "20230115032823-scraping.md" >}}), [peer-to-peer]({{< relref "20221101184751-peer_to_peer.md" >}})

![](/ox-hugo/20230115032923-archival-1789170364.png)
![](/ox-hugo/20230115032923-archival-547001898.png)

[38% of webpages that existed in 2013 are no longer accessible a decade later | Hacker News](https://news.ycombinator.com/item?id=40397692)


## Orgs and Projects {#orgs-and-projects}


### Big ones {#big-ones}


#### IA (Internet Archive) {#ia--internet-archive}

-   <https://archive.org/>
-   American digital library with the stated mission of "universal access to all knowledge."
-   Owns waybackmachine
-   archive.org launched in 2001.
-   [Making IIIF Official at the Internet Archive | Internet Archive Blogs](https://blog.archive.org/2023/09/18/making-iiif-official-at-the-internet-archive/)


#### Archive Team {#archive-team}

-   <https://wiki.archiveteam.org/>
-   Archive Team is a loose collective of rogue archivists, programmers, writers and loudmouths dedicated to saving our digital heritage.
-   archive.is launched in 2012.


#### Z-library {#z-library}

-   Z-Library was essentially a clone of LibGen with a more accessible UX and monetization. Though I believe they eventually solicited new material that was not fed back into LibGen.
-   Basically libgen has more strict requirements on metadata, fiction/non fiction split, so it makes meeting difficult.
-   <https://annas-blog.org/help-seed-zlibrary-on-ipfs.html>
-   <https://annas-blog.org/blog-3x-new-books.html>
-   [The code for Anna's Archive | Hacker News](https://news.ycombinator.com/item?id=37282469)
-   [Anna’s Archive: Open-source data library | Hacker News](https://news.ycombinator.com/item?id=36530662)
-   <https://annas-blog.org/putting-5,998,794-books-on-ipfs.html>
-   [Anna's Archive - Wikipedia](https://en.wikipedia.org/wiki/Anna%27s_Archive)


#### sci-hub {#sci-hub}

-   [Sci-Hub: knowledge as a human right | Hacker News](https://news.ycombinator.com/item?id=34541505)
-   [Reddit - Dive into anything](https://www.reddit.com/r/DataHoarder/comments/nc27fv/rescue_mission_for_scihub_and_open_science_we_are/)
-   [How to circumvent Sci-Hub ISP block | Hacker News](https://news.ycombinator.com/item?id=27451844)
-   [Archivists Are Trying To Save Sci-Hub](https://gizmodo.com/archivists-want-to-make-sci-hub-un-censorable-1846898276)
-   [Sci-Hub - Wikipedia](https://en.wikipedia.org/wiki/Sci-Hub#cite_note-:12-31)


#### bellingcat {#bellingcat}

Not really an archiving org but has related projects

-   <https://github.com/bellingcat/auto-archiver>


### Others {#others}

-   <https://perma.cc/>
-   Megalodon
-   <https://bitsavers.org/>


### Indian {#indian}

-   <https://github.com/DigitalIndiaArchiver>


## Wikipedia {#wikipedia}

-   Wikipedia needs to have a separate section of its own
-   Wikitext is the name of the markup language that MediaWiki uses.
-   MediaWiki includes a parser for WikiText into HTML, and this parser creates the HTML pages displayed in your browser.


### Related tools {#related-tools}

-   <https://github.com/openzim/mwoffliner>
-   <https://github.com/zverok/wikipedia_ql>
-   <https://github.com/spencermountain/wtf_wikipedia>
-   <https://github.com/daveshap/PlainTextWikipedia>
-   [Deletionpedia](http://deletionpedia.dbatley.com/w/index.php)


## Archiving formats {#archiving-formats}

-   WARC
-   <https://en.wikipedia.org/wiki/HAR_(file_format)>
-   WORM?
-   <https://en.wikipedia.org/wiki/MHTML>
-   <https://wiki.openzim.org/wiki/OpenZIM>


## Usecases {#usecases}


### Website downloaders {#website-downloaders}

-   We can use `wget` and `httrack` for downloading entire sites. See my `offlinesavesite` alias for more info
-   [Skallwar/suckit](https://github.com/Skallwar/suckit): Alternative to httrack?
-   [Y2Z/monolith](https://github.com/Y2Z/monolith): Downloads assets as data urls(unlike `wget -mpk`) into 1 single HTML file
-   [WebMemex/freeze-dry](https://github.com/WebMemex/freeze-dry) : Not a tool, but a library. Seems outdated, but still useful. Has a nice "how it works" page.
-   [gildas-lormeau/SingleFile](https://github.com/gildas-lormeau/SingleFile) : Decent extension/cli


### Artifact extraction {#artifact-extraction}

-   [simonw/shot-scraper](https://github.com/simonw/shot-scraper)
    -   While this can be used to take screenshots(full/partial/can even do modifications w js before ss)
    -   The ss are pixel perfect and you can specify size, so unless nothing changed, git diff will have no change to show as-well. good for us.
    -   It does not do change detection but [can be used](https://usrme.xyz/posts/leveraging-shot-scraper-and-creating-image-diffs/) for that purpose. (See [Image Compression]({{< relref "20230113141102-image_compression.md" >}}) for related tools)
    -   Original usecase was to keep the screenshots included in documentation site uptodate.
    -   Can also be used for extraction of text data


### Offline browsing {#offline-browsing}

-   [dosyago/DownloadNet](https://github.com/dosyago/DownloadNet): Does similar stuff like downloading a site but more for offline browsing


## Tools {#tools}


### Traditional tools/enterprisey stuff {#traditional-tools-enterprisey-stuff}

-   <https://github.com/artefactual/archivematica>
-   <https://github.com/projectblacklight/spotlight>


### WaybackMachine {#waybackmachine}

-   <https://github.com/sangaline/wayback-machine-scraper>
-   <https://github.com/uriel1998/muna>
-   <https://github.com/tomnomnom/waybackurls>


### Misc old school tools {#misc-old-school-tools}

-   <https://github.com/danderson/mixtape>


### Others {#others}

-   [Rrweb – record and replay debugger for the web | Hacker News](https://news.ycombinator.com/item?id=41030862)


### Youtube {#youtube}

-   <https://www.tubearchivist.com/>
-   <https://pastebin.com/s6kSzXrL>
-   <https://danielmiessler.com/p/rss-feed-youtube-channel/>
-   <https://github.com/jchv/ytdl-pvr>
