+++
title = "Floating Point"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Math]({{< relref "20221101134840-math.md" >}})


## Introduction {#introduction}

FP are just scientific notion

-   Two important advantages:
    -   Speed: The speed of floating-point operations, commonly measured in terms of `FLOPS`
    -   Efficiency : Can deal with really big and small numbers without needing large amount of space.
-   A floating-point unit(FPU) is a part of the processor specifically designed to carry out floating-point numbers ops.
-   About bases
    -   In practice, most floating-point numbers use `base 2`, though `base10` (decimal floating point) is also common, there are also other bases used for FP.
    -   The base determines the fractions that can be represented; for instance, 1/5 cannot be represented exactly as a floating-point number using a binary base, but 1/5 can be represented exactly using a decimal base (0.2, or 2Ã—10âˆ’1)

> The term floating point refers to the fact that the number's radix point can "float" anywhere to the left, right, or between the significant digits of the number. This position is indicated by the exponent, so floating-point can be considered a form of scientific notation.


## Anatomy {#anatomy}

-   **significand**: A signed (+/-) digit string of a given length in a given base (or radix).
    -   This digit string is referred to as the `significand`, `mantissa`, or `coefficient`.
    -   The length of the `significand determines the precision` to which numbers can be represented.
        -   An example, in the binary single-precision (32-bit) floating-point representation, `p=24`, and so the significand is a string of 24 bits.
-   **exponent**: A signed integer exponent (also referred to as the `characteristic`, or `scale`)
    -   Modifies the magnitude of the number.


## Glossary {#glossary}


### Precision {#precision}

In the IEEE 754-2008 standard, the 64-bit base-2 format is officially referred to as binary64; it was called double in IEEE 754-1985. So there are other changes like this. Make a list (TODO)

-   16-bit: Half (binary16)
-   32-bit: Single (binary32), decimal32
-   64-bit: Double (binary64), decimal64


## Languages usage {#languages-usage}


### Javascript {#javascript}

JS has just two number types:

-   `number` which uses `double-precision 64-bit binary format IEEE 754` or `binary64`.
    -   safely represented between -(2<sup>53</sup> âˆ’ 1) and 2<sup>53</sup> âˆ’ 1 without loss of precision. See `Number.MIN_SAFE_INTEGER` and `Number.MAX_SAFE_INTEGER`
    -   `Number.MAX_VALUE` is the largest number possible to represent using a double precision floating point representation.
    -   `Number.MAX_SAFE_INTEGER` is the largest integer which can be used safely in calculations.
-   `BigInt`
    -   numeric primitive in JavaScript that can represent integers with [arbitrary precision](https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic).
    -   makes it possible to correctly perform integer arithmetic without overflowing.


## Resources {#resources}

-   [Floating Point Math](https://0.30000000000000004.com/) ðŸŒŸ
-   [Why does 0.1 + 0.2 = 0.30000000000000004?](https://jvns.ca/blog/2023/02/08/why-does-0-1-plus-0-2-equal-0-30000000000000004/)
-   [Examples of floating point problems](https://jvns.ca/blog/2023/01/13/examples-of-floating-point-problems/) ðŸŒŸ
-   [Floating-point arithmetic - Wikipedia](https://en.wikipedia.org/wiki/Floating-point_arithmetic)
-   <https://en.wikipedia.org/wiki/Significand>
-   <https://en.wikipedia.org/wiki/Floating-point_arithmetic>
-   <https://en.wikibooks.org/wiki/A-level_Computing/AQA/Paper_2/Fundamentals_of_data_representation/Floating_point_numbers>
-   [Supporting half-precision floats is really annoying (2021) | Hacker News](https://news.ycombinator.com/item?id=34396925)
