+++
title = "SQL"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Database]({{< relref "20221102123145-database.md" >}}), [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}})


## FAQ {#faq}


### Document Data Model (NoSQL) {#document-data-model--nosql}

![](/ox-hugo/20230217190123-sql-51728771.png)
![](/ox-hugo/20230217190123-sql-1802579951.png)


### History? {#history}

-   Berkeley, for `Ingress` had `QUEL`
    -   `Ingress` roots [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}})
-   IBM, for `System R` first came up w `SQUARE`
    -   `System R` roots `System/38`, `DB2`
    -   `SQUARE` was complicated, so needed something else.
    -   Came up with `SEQUEL`, wordplay on `QUEL` (sequel to `QUEL`)
    -   Later renamed `SEQUEL` to `SQL`


### Why is COUNT(\*) slow? {#why-is-count-----slow}

-   `SELECT COUNT(*) FROM students;`
-   This is same as `SELECT COUNT(1) FROM students;`
-   So we can say "why is `SELECT COUNT(1) FROM students;` slow?"
-   In [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}})
    -   It's because of [MVCC]({{< relref "20231116004530-mvcc.md" >}})
    -   Multiple transactions see different states
    -   PG needs to know which rows are "visible", and "visibility" depends on the [Isolation level]({{< relref "20231113121413-concurrency_consistency_models.md" >}}) and [MVCC]({{< relref "20231116004530-mvcc.md" >}}) implementation.
    -   Eg. If some concurrent write access is happening on some row that will not be visible in certain isolation level. So we need to row by row.
-   smol hack: We can instead get the estimate using json output of `EXPLAIN`
-   [Faster PostgreSQL Counting](https://www.citusdata.com/blog/2016/10/12/count-performance/)


### Why is SELECT \* slow? {#why-is-select-slow}

-   `SELECT * from students;`
-   It's even worse in column store
-   [A Deep Dive in How Slow SELECT \* is - YouTube](https://www.youtube.com/watch?v=wybjsKtA9hI)


## SQL and Relational Algebra {#sql-and-relational-algebra}

<div class="warning small-text">

> -   SQL is based on **bags (duplicates)** not **sets (no duplicates)**.
> -   So this is where SQL differs from relation algebra
</div>


### Queries {#queries}


#### DML {#dml}

-   Methods to store and retrieve information from a database.
-   Procedural
    -   Query specifies a high-level "How" based on sets.
    -   This is Relational Algebra
-   Non-Procedural (Declarative)
    -   Query specifies only what data is needed.
    -   This is Relational Calculus
-   Eg. `SELECT, INSERT, UPDATE, DELETE, TRUNCATE`


#### DDL {#ddl}

-   Index creation, table creation deletion etc.
-   Eg. `CREATE, DROP, ALTER`


#### DCL (Data control language) {#dcl--data-control-language}

-   Access control etc.
-   Eg. `GRANT, REVOKE`


#### Other modifiers {#other-modifiers}

-   Basic: `WHERE, ORDER BY, JOIN`
-   Merge: `DISTINCT`
    -   It operates on the entire row(eg. if you SELECT multiple cols)
-   Aggregate: `GROUP BY, HAVING`
-   Limit: `LIMIT, OFFSET`
-   Set operations: `UNION, INTERSECT, EXCEPT`
    -   `EXCEPT` is the `difference` from [Set Theory]({{< relref "20231019150045-set_theory.md" >}})


#### Transaction control {#transaction-control}

-   Eg. `BEGIN, COMMIT, ROLLBACK, SAVEPOINT, RELEASE SAVEPOINT`


### Operators {#operators}

{{< figure src="/ox-hugo/ra_hand_note.jpg" >}}

-   relational algebra is a logical definition of what a plan should do


### Ordering {#ordering}

-   Ordering is important, do we want to join 1bnx1bn and then pick columns or do we want to join 1bnx2cols. The latter is better.
    ![](/ox-hugo/20230217190123-sql-89523410.png)
-   This translates to execution strategy/query plan
-   Modern optimizers can sometime help you do this automatically but sometimes it gets things wrong.
-   TIP: Don't prematurely optimize, write your query normally, see what the optimizer does, if not what you need, change your query/provide hints/provide index etc.
-   Also when you write a SQL query, the order that the SQL query is written in, is not the order that it actually happens in. But irl db(s) have other optimizations aswell


### Practicality {#practicality}

-   SQL has a standard but almost every dbms vendor offends the standard


## 101 Basics {#101-basics}


### Query {#query}

{{< figure src="/ox-hugo/20230217190123-sql-920763669.png" >}}


#### Parameterized Query {#parameterized-query}

-   Query that uses placeholders for parameters instead of embedding the actual values directly in the query string. Replacement happens at `execution/run time` and **not** at query planning time.
-   Prevents SQL injection. Makes sure to treat `parameters` as `data` and not as executable parts of the SQL statements.
-   Eg. `LIKE` : `%` (any substring), `_` (one character)


#### Prepared statement {#prepared-statement}

-   Uses `PREPARE`, [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}}) pre-compiles the SQL query. Improves performance.
-   Creates a server side object. But only for the DB session.
-   `EXPLAIN EXECUTE name(parameter_values);` to see generic or custom plan
-   Features
    -   Can use `EXECUTE` to execute the statement
    -   You can also specify the types of the parameters
    -   Useful when a single session is being used to execute a large number of similar statements.
    -   Refer to parameters by position, using $1, $2, etc.


### Output {#output}


#### String operations {#string-operations}

{{< figure src="/ox-hugo/20230217190123-sql-1746515094.png" >}}

-   Operations: Can be used in `output` or in `predicate`
    -   Eg. `SUBSTRING`, `UPPER`, `||/+/CONCAT`,  DBMSes add their own shit


#### Date/Time {#date-time}

-   Can be used in `output` or in `predicate`


#### Output redirection {#output-redirection}

![](/ox-hugo/20230217190123-sql-2071905278.png)
![](/ox-hugo/20230217190123-sql-1373880548.png)


#### Output control {#output-control}

<!--list-separator-->

-  ORDER BY

    {{< figure src="/ox-hugo/20230217190123-sql-949781639.png" >}}

    -   The database will store the tuples any way it wants
        -   No guarantee that it'll store data in the way you insert them
    -   Can use the `ORDER BY <column*/offset> [ASC|DSC]` clause to re-order the results
        -   Default order is `ASC`
        -   We can use `offset` number in cases where we run orderby in cases the column doesn't have a name
    -   Interesting thing is, I can `ORDER BY` some column even if that column is not mentioned in the `SELECT` statement.
    -   We can also `ORDER BY` on a column alias created by `SELECT` using `AS`

<!--list-separator-->

-  LIMIT

    -   `LIMIT <count> [offset]`
        ![](/ox-hugo/20230217190123-sql-1508611219.png)


### Views {#views}


#### Regular views {#regular-views}

-   A non-materialized VIEW is a name for a `SELECT` statement
    -   Query that pretends to be a table
    -   In [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}}) you use `VIEW` to name a `SELECT` statement
    -   Building views upon other views is not uncommon.
-   It directly works with actual data
-   Uses
    -   Abstraction: Diff tables into one
    -   Security/Privacy: Expose only the shit you want to expose, [don't show too much cock](https://www.youtube.com/watch?v=cS2b0HT_xUU)


#### Materialized views {#materialized-views}

{{< figure src="/ox-hugo/20230217190123-sql-641918081.png" >}}

-   Work best for expensive views on data that does not change frequently.
-   If a view is cheap/fast or changes to the underlying data occur frequently, you probably do not want to materialize it.
-   update all rows and set read locks on all affected data during refreshment by default.
-   We can materializing a view into a temp table
    -   The temp table cannot be directly updated, but can be refreshed using `REFRESH MATERIALIZED VIEW <table_name>;`
    -   See [PostgreSQL: Documentation: 16: 41.3.Â Materialized Views](https://www.postgresql.org/docs/current/rules-materializedviews.html)
-   See [How PostgreSQL Views and Materialized Views Work and How They Influenced TimescaleDB Continuous Aggregates](https://www.timescale.com/blog/how-postgresql-views-and-materialized-views-work-and-how-they-influenced-timescaledb-continuous-aggregates/)


#### `Views` v/s `CTE` v/s Materialized view {#views-v-s-cte-v-s-materialized-view}

-   CTE are sometimes called `inline view`

| X           | View                      | CTE                                  | Materialized View    |
|-------------|---------------------------|--------------------------------------|----------------------|
| Lifetime    | Q is object in DB         | Exists only for duration of Q        | Caches data and Q    |
| USP         | Can be used in multiple Q | Good w tree hierarchy i.e. recursive |                      |
| Index       | Index can be created      | No statistics, No indexes            |                      |
| Performance | Does nothing              | Does nothing                         | Improves Performance |


### Procedures {#procedures}


#### Nested Queries / Sub Queries / Inner Queries {#nested-queries-sub-queries-inner-queries}

![](/ox-hugo/20230217190123-sql-1639044269.png)
![](/ox-hugo/20230217190123-sql-1073125166.png)
![](/ox-hugo/20230217190123-sql-279703104.png)

-   Embed one query inside another
-   Inner query can reference outer query table
-   Difficult to optimize, the optimizer will try to optimize it into a JOIN or do something else etc.
    ![](/ox-hugo/20230217190123-sql-914805055.png)


#### Common Table Expression (CTE) {#common-table-expression--cte}

![](/ox-hugo/20230217190123-sql-2040450241.png)
![](/ox-hugo/20230217190123-sql-1429180967.png)
![](/ox-hugo/20230217190123-sql-1834342390.png)

-   Mostly about `WITH`
    -   `WITH` are the "private methods" of SQL
    -   `WITH` is a prefix to SELECT
    -   `WITH` queries are only visible in the SELECT they precede
-   Separated by `,` and returns to main query if no `,` (comma)
-   Better alternative to nested queries and views
-   Statement scoped views
-   Provides a way to write auxiliary statements for use in a larger query.
-   Think of it like a temp table just for one query.
-   Has a `RECURSIVE` version. Makes SQL Turing Complete (See [Automata Theory]({{< relref "20230421132238-automata_theory.md" >}})) because it allows [Recursion]({{< relref "20230429205506-recursion.md" >}})
    ![](/ox-hugo/20230217190123-sql-1558611556.png)
    ```sql
    WITH RECURSIVE source (
        counter
    ) AS ((
            SELECT
                1)
        UNION (
            SELECT
                counter + 1
            FROM
                source
            WHERE
                counter < 10))
    SELECT
        *
    FROM
        source;
    ```


### JOINs {#joins}

See [SQL JOINs]({{< relref "20231019134157-sql_joins.md" >}})


## NULL in SQL {#null-in-sql}

-   `NULL` is never equal or not equal to "anything" in SQL. Not even to itself.
    -   `=` and `!=` operators don't work with `NULL`


### What `NULL` means depends on the data {#what-null-means-depends-on-the-data}

-   It can mean missing data
-   It can mean the data has the `NULL` value, whatever the application then interprets
-   Where they come from (some examples)
    -   Table/Data can have it in itself
    -   Functions (eg. `LAG`) can return `NULL`
    -   Result of some OUTER JOIN
    -   Any operations such as `+`, `*`, `CONCAT` with `NULL` will result in `NULL`


### Handling `NULL` {#handling-null}

-   Handle them in application
-   Filter them
-   If you have `IS NULL` sprinkled across every query, that tells me that you have a lot of nullable columns in your schema that really ought to be not-nullable. You should be enforcing non-nullableness on your database table, not your `SELECT`.
-   `COALESCE`
    -   `COALESCE` returns the first item that is not `NULL`
    -   items in the list should be of same type
    -   items can be literal or other columns too
-   `CASE`
    -   This is how you'd write `if` statements in SQL
        ![](/ox-hugo/20230217190123-sql-1079475229.png)


### `NULL` and Unique indexes {#null-and-unique-indexes}

`NULL` in not equal to `NULL`, so if you try to add a unique constraint or unique index on a column, it's allowed to have multiple `NULL` values. unless something like `NULLS NOT DISTINCT` is used. (PG)


## Aggregations {#aggregations}

{{< figure src="/ox-hugo/20230217190123-sql-286460954.png" >}}

-   Both `GROUP BY` and `OVER` may follow any aggregation


### Aggregation Functions {#aggregation-functions}

-   `COUNT(col)`: Return # of values for col.
-   `SUM(col)`: Return sum of values in col.
-   `AVG(col)`: Return the average col value.
-   `MIN(col)`: Return minimum col value.
-   `MAX(col)`: Return maximum col value.


### GROUP BY {#group-by}

-   Functions that return a single value from a bag of `tuples`
-   Aggregate functions can **(almost) only be used** in the `SELECT` output list.
-   Support/Rules
    -   `COUNT, SUM, AVG` support `DISTINCT`
    -   Multiple aggregates in a `SELECT` query is allowed
    -   Output of other columns when doing aggregates is undefined. (instead use `GROUP BY`)
    -   Non-aggregated values in `SELECT` clause must appear in `GROUP BY` clause.
    -   Filtering on the aggregated value is done using `HAVING`, syntax looks like we're computing `AVG` twice, but the database is smart enough not to do that. We use `HAVING` because `WHERE` is not aware of the computed value.
        ![](/ox-hugo/20230217190123-sql-2019727508.png)
    -   **IMPORTANT**: `HAVING` filters after the `GROUP BY`, `WHERE` filters before `GROUP BY`


### Window Functions {#window-functions}

See [Window Functions in SQL]({{< relref "20231019212748-window_functions_in_sql.md" >}})


## Data Modeling {#data-modeling}

See [RDBMS / SQL / DB Data Modeling]({{< relref "20231114082501-rdbms_sql_db_data_modeling.md" >}})


## Random topics {#random-topics}

-   [Rivers and Axis | ProGramin'g thoughts](https://gramin.pro/posts/rivers-and-axis/)
-   "say you have a dataset in a SQL table, and you find there are duplicates in it that shouldn't be there. walk me through how you'd resolve this issue"
    -   I've also encountered the same thing, but with constraints added every time you come up with a solution.
    -   Whay if the table has a billion rows, would that affect your solution?
    -   What if you need to ensure it completes before every full hour?
    -   What if new data arrives continuously?
