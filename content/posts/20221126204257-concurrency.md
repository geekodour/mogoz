+++
title = "Concurrency"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Operating Systems]({{< relref "20221101172456-operating_systems.md" >}}), [Systems]({{< relref "20221101150250-systems.md" >}})


## Concurrent V/S Parallel {#concurrent-v-s-parallel}

<div class="warning small-text">

> The use of word "thread" is not very strict here.
</div>

-   Parallelism is a subset of concurrency
-   Concurrent is 1 queues and 1 coffee machine. Parallel is 2 queues and 2 coffee machines.
-   Concurrency is juggling, parallelism is using two hands to do it
-   Concurrency is what you use to make it correct, parallelism is to make it faster.
-   In practice
    -   If you had `single core` and `multiple threads`, those threads will be run concurrently. Eg. only one thread at a time, but **no thread can assume any other thread's current state**.
    -   If you have `multiple cores`, it is possible to achieve parallelism by running `two threads at exactly the same time`.
-   Example
    -   Concurrent: Internals of a web server
    -   Parallel: Google's MapReduce

{{< figure src="/ox-hugo/20221126204257-concurrency-1512579699.png" >}}


### Concurrency {#concurrency}

{{< figure src="/ox-hugo/20221126204257-concurrency-1421013282.png" >}}

-   Multiple things are in the middle of running, and they have to communicate/coordinate with each other in order to **get the overall job done**. This means, **more work for the scheduler** as things are dependent on order of execution.
-   Concurrency is a **way to organize code**: pieces of your program get more flexible ways to communicate with each other than just call/return.
-   Concurrency is important when you're doing anything where the CPU has to wait. For example, network and disk heavy workloads.
-   Part of the value of concurrency is that it can highlight opportunities for parallelism.
-   If the processes are independent of each other you're not guaranteed to benefit from concurrency, especially if you only have 1 core.
-   **Doing it wrong causes:** Semantically wrong behavior (producing the wrong result, failing to produce a result at all).


### Parallelism {#parallelism}

{{< figure src="/ox-hugo/20221126204257-concurrency-1149897538.png" >}}

-   Multiple things are in the middle of running, and several of them make progress simultaneously.
-   Parallelism is a **way to speed up code**: pieces of your program don't have to all wait their turn while one task at a time executes.
-   If the processes are independent of each other:
    -   You can distribute those calculations to 8, 16 or 32+ cores and significantly cut down your runtime.
        ![](/ox-hugo/20221126204257-concurrency-614463799.png)
    -   It's a promise by the user to the scheduler that the result of the code will be correct however it is scheduled to run.
-   **Doing it wrong causes:** inferior performance.
-   We can use concurrent mechanism(eg. thread pools) to run parallel code but it'll be slow. Because, now the user is not giving the scheduler the guarantee that there are no cross-task dependencies.


### Serial {#serial}

{{< figure src="/ox-hugo/20221126204257-concurrency-1647421493.png" >}}


## Concurrency Styles {#concurrency-styles}

<div class="warning small-text">

> This is not a strict list, just trying to categorize shit i see in the wild. The terminologies are so confusing. someone needs to make a feature matrix or something, maybe by language and make it the defacto thing when ppl argue about these things. These ideas can be using together, some might be othogonal etc.
</div>


### Thread based {#thread-based}

-   Can share memory/ or not
-   Uses things like locks, mutexes, countdowns, condition variables, semaphores etc.
-   A sequential flow of control within a process.


### Coroutine based {#coroutine-based}

-   Implies supporting of explicit means for transferring control to another coroutine.
-   Coroutine is a chunk of code than can voluntarily suspend itself. i.e yield
-   [How itch.io uses Coroutines for non-blocking IO](https://leafo.net/posts/itchio-and-coroutines.html)


### Fibers {#fibers}


### Green Threads {#green-threads}

-   [Green thread - Wikipedia](https://en.wikipedia.org/wiki/Green_thread)
-   Green threads have threading semantics, that means that you need to deal with mutexes, atomics, etc.
-   You should code as though the context can switch at any time
-   Python's greenlets


### Event Queue {#event-queue}

{{< figure src="/ox-hugo/20221126204257-concurrency-68786927.png" >}}

-   One a single thread exists!
-   A single loop reads from the event queue and invokes the handlers.


### Actor Model {#actor-model}

-   See [Actor Model]({{< relref "20221101221524-actor_model.md" >}})
-   No concept of "events", "threads" or a "processes", only Actors and messages.


### CSP {#csp}

-   [Communicating sequential processes - Wikipedia](https://en.wikipedia.org/wiki/Communicating_sequential_processes#Comparison_with_the_actor_model)


### Async/Await {#async-await}

-   async/await only will switch context at a yield point
-   [Async/await - Wikipedia](https://en.wikipedia.org/wiki/Async/await)


### Instruction level {#instruction-level}


#### SIMD &amp; MIMD {#simd-and-mimd}

See [Flynn's Taxonomy]({{< relref "20230408161230-flynn_s_taxonomy.md" >}})


#### GPGPU {#gpgpu}

See [GPGPU]({{< relref "20230408051445-gpgpu.md" >}})


### Statement level based {#statement-level-based}

-   Language syntax based.
-   `channels` and `groutines` in [Golang]({{< relref "20221101220915-golang.md" >}}).
-   Atomic operations in languages


### Distributed {#distributed}

-   Multiprocessor and Multi-computer stuff


## Modeling concurrency {#modeling-concurrency}

See [Formal Methods]({{< relref "20230403235716-formal_methods.md" >}})


### Non-realtime interleaved execution model {#non-realtime-interleaved-execution-model}

-   Study of interleaved execution sequences of atomic instructions
-   Each of the instructions
    -   Executes arbitrarily
    -   In finite amount of time.
    -   Can take many interleavings
-   No assumption of
    -   Relative speed of instructions
    -   How the scheduler is working

{{< figure src="/ox-hugo/20221126204257-concurrency-1787925353.png" >}}


## Correctness {#correctness}


### What Hoare said {#what-hoare-said}


#### Partial Correctness {#partial-correctness}

```text
if precondition & program terminates
  postconditions remain same (holds)
end
```

-   If an answer is returned
    -   It will be correct
-   This [can be proven](https://en.wikipedia.org/wiki/Hoare_logic#Partial_and_total_correctness) via [Correctness criteria](#correctness-criteria)


#### Total Correctness {#total-correctness}

```text
if precondition
  terminate program & postconditions remain same (holds)
end
```

-   If an answer is returned
    -   It will be correct
    -   It will return(terminate)
-   [Proving if a program](https://en.wikipedia.org/wiki/Correctness_(computer_science)) will terminate is undecidable


### Correctness criteria {#correctness-criteria}

Properties of a program are mathematical statements we can make about itâ€™s traces.


#### Safety properties (Always hold, BTNH) {#safety-properties--always-hold-btnh}

-   Bad things never happen
-   Requires only one counter example to refute
-   What to prove?
    -   Never does the wrong thing
    -   Never spits out the wrong answer
    -   Never violates invariants during execution
-   Most of us have a natural intuition for safety properties as programmers.
-   Example: Crash like things, Vulnerabilities, Memory errors etc.


#### Liveness properties (Eventually hold, GTAH) {#liveness-properties--eventually-hold-gtah}

-   Good things always happen
-   What to prove?
    -   A **finite proof of progress** resulting in the result we need
-   Example: Guaranteed availability, and termination


## Concurrency primitives {#concurrency-primitives}


### Mutex (Mutual Exclusion Lock) {#mutex--mutual-exclusion-lock}

-   Mutex guarantees that checking or modifying the value of a semaphore can be done safely
-   **OS guarantees** not to create a race condition between threads attempting to use the lock.


### Semaphores + Mutex {#semaphores-plus-mutex}

```text
lock := acquire_a_lock()
register := read_balance()
register += 100
write_balance(register)
release_lock()
```

-   +ve counter that can be used to synchronize multiple threads.


### Condition Variables + Mutex {#condition-variables-plus-mutex}

```text
critical_section do
  register := read_balance()
  register += 100
  write_balance(register)
end
```

-   Implement more complex conditions under which threads execute.
-   Generally used to
    -   Avoid busy waiting while waiting for a resource to become available.
    -   Instead, implement a condition under which a thread executes
    -   Inversely, implement a condition under which the thread is blocked


### Semaphores vs Condition Variables {#semaphores-vs-condition-variables}

-   Semaphores and condition variable can be used together
-   Condition variables has no counter/memory unlike semaphores.


### Lockless {#lockless}

-   [It's "locking" if it's blocking](https://www.reddit.com/r/programming/comments/15kbp4/its_locking_if_its_blocking_a_definition_lockfree/)
-   [An Introduction to Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)


## Concurrency issues {#concurrency-issues}


### Race conditions {#race-conditions}

{{< figure src="/ox-hugo/20221126204257-concurrency-993213316.png" >}}

-   Result depends on: Relative timing of events in the threads.
-   Can exist on both single core and multicore systems.


#### Solution: Mutex Lock + Critical Section (atomic) {#solution-mutex-lock-plus-critical-section--atomic}

-   Only 1 process deals w `critical section` at a given time.
-   Critical section is basically chunking subsequences into atomic instruction
-   Now this solves Race conditions, but causes other issues like `deadlock`, `livelock`, `starvation`, `reliability`


### Deadlocks {#deadlocks}

-   One or more threads are stuck waiting for something that never will occur. Something only the other thread which is also blocked can unblock.
    ```text
        TX 1 asks, gets lock A
        TX 2 asks, gets lock B
        TX 1 asks, blocks waiting for lock B (held by TX 2)
        TX 2 asks for lock A. Boom!
    ```
-   Can be solved via understanding the order and re-thinking.


### Livelock {#livelock}

-   No progress is made because
    -   Each thread tries to enter its critical section
    -   then times out, then tries again, and so on, forever.
-   Can be solved via some jitter or something


### Starvation {#starvation}

-   Put upper bound on the time a process enters critical section while others wait.


### Reliability ðŸŒŸ {#reliability}

-   Thread crashes in the middle of the critical section. What now?
-   Thread also could be holding lock other processes wait for. Too bad now.
-   It's developer responsibility to make sure that critical sections are short and they terminate.


## Concurrency communication {#concurrency-communication}

-   See [Inter Process Communication]({{< relref "20221101173527-ipc.md" >}})


## Scheduling {#scheduling}

-   M processors and N threads. If M &lt; N you need a scheduler
-   In operation of a scheduler, `thread` can have many `states`


## By Language {#by-language}


### Javascipt {#javascipt}

-   See [Javascript Runtime and Browser]({{< relref "20221127082259-javascript_runtime.md" >}})
-   The single-threaded model has made Node.js a popular choice for server-side programming due to its non-blocking IO, making handling a large number of database or file-system requests very performant.
-   However, CPU-bound (computationally intensive) tasks that's pure JavaScript will still block the main thread.
-   To achieve real paralleling, you may need to use [workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers).
-   A web worker or a cross-origin iframe has its own stack, heap, and message queue.


### Golang {#golang}

See [Golang]({{< relref "20221101220915-golang.md" >}}), [Concurrency in Golang]({{< relref "20230412015037-concurrency_in_golang.md" >}})


### Rust {#rust}

-   Rust offers safety from data races(not race conditions)


## Resources {#resources}

-   [introconcurrency](https://cs.lmu.edu/~ray/notes/introconcurrency/)
-   [Process calculus - Wikipedia](https://en.wikipedia.org/wiki/Process_calculus)
