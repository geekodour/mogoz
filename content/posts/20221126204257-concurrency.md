+++
title = "Concurrency"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Operating Systems]({{< relref "20221101172456-operating_systems.md" >}}), [Systems]({{< relref "20221101150250-systems.md" >}})


## Concurrent V/S Parallel Programming {#concurrent-v-s-parallel-programming}

-   Parallelism is a subset of concurrency
-   Concurrent is 1 queues and 1 coffee machine. Parallel is 2 queues and 2 coffee machines.
-   Concurrency is juggling, parallelism is using two hands to do it
-   Concurrency is what you use to make it correct, parallelism is to make it faster.
-   In practice
    -   If you had `single core` and `multiple threads`, those threads will be run concurrently. Eg. only one thread at a time, but **no thread can assume any other thread's current state**.
    -   If you have `multiple cores`, it is possible to achieve parallelism by running `two threads at exactly the same time`.


## Concurrency {#concurrency}

-   Multiple things are in the middle of running, and they have to communicate/coordinate with each other in order to **get the overall job done**.
-   Concurrency is a **way to organize code**: pieces of your program get more flexible ways to communicate with each other than just call/return.
-   Concurrency is important when you're doing anything where the CPU has to wait. For example, network and disk heavy workloads.
-   Part of the value of concurrency is that it can highlight opportunities for parallelism.
-   If the processes are independent of each other you're not guaranteed to benefit from concurrency, especially if you only have 1 core.
-   **Doing it wrong causes:** Semantically wrong behavior (producing the wrong result, failing to produce a result at all).


## Parallelism {#parallelism}

-   Multiple things are in the middle of running, and several of them make progress simultaneously.
-   Parallelism is a **way to speed up code**: pieces of your program don't have to all wait their turn while one task at a time executes.
-   If the processes are independent of each other:
    -   You can distribute those calculations to 8, 16 or 32+ cores and significantly cut down your runtime.
    -   Otherwise, parallel code often requires some concurrency when tasks share intermediate results with each other.
-   **Doing it wrong causes:** inferior performance.


## Execution {#execution}

> I am somewhat on the fence about the parallel execution and parallelism distinction here. Read it someone's blog.


### Parallel Execution vs parallelism {#parallel-execution-vs-parallelism}

-   Parallel execution != parallelism
-   Parallel execution is when a computer has more than one CPU or CPU core, and makes progress on more than one task simultaneously.


### Parallel Concurrent Execution {#parallel-concurrent-execution}

-   Threads are distributed among multiple CPUs.
-   Threads executed on the same CPU are executed concurrently
-   Threads executed on different CPUs are executed in parallel.


## Concurrency in Javascipt {#concurrency-in-javascipt}

-   The single-threaded model has made Node.js a popular choice for server-side programming due to its non-blocking IO, making handling a large number of database or file-system requests very performant.
-   However, CPU-bound (computationally intensive) tasks that's pure JavaScript will still block the main thread.
-   To achieve real paralleling, you may need to use [workers](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers).
-   A web worker or a cross-origin iframe has its own stack, heap, and message queue.
