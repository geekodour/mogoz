+++
title = "Lockfree"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Concurrency]({{< relref "20221126204257-concurrency.md" >}})


## Resources {#resources}

-   [An Introduction to Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)
-   [1024cores - Introduction](https://www.1024cores.net/home/lock-free-algorithms/introduction)
-   [CppCon 2014: Herb Sutter "Lock-Free Programming (or, Juggling Razor Blades)](https://www.youtube.com/watch?v=c1gO9aB9nbs)
-   [CppCon 2017: Fedor Pikus “C++ atomics, from basic to advanced.""](https://www.youtube.com/watch?v=ZQFzMfHIxng)


## FAQ {#faq}


### What is Non-blocking algorithm? {#what-is-non-blocking-algorithm}

An algorithm is non-blocking if the delay of some threads cannot delay other threads indefinitely


### What is Lockless? {#what-is-lockless}

|              | Lock less           | Lock based          |
|--------------|---------------------|---------------------|
| Blocking     | X                   | Mutexes and Friends |
| Non-blocking | Atomics and friends | X                   |

-   I don't know what is lockless. It's a confusing term. I'll not use this term.
-   Locking is how you implement for blocking
-   Atomicity is how you implement non-blocking


### Why Non-blocking algorithms? {#why-non-blocking-algorithms}

-   You usually don't need non-blocking algorithms. Locking/blocking algorithms are just fine for most cases.
-   What non-blocking algorithms primarily offer is varying range of **forward progress** guarantees.
-   As a side effect of it, there might be some performance gains. In general lockfree algorithms are slower than analogous algorithms not burdened with forward progress guarantees
-   So, you want to look at Non-blocking algorithms if your system requires the forward progress gurantees these algorithms provide.


## Termination safety/Forward progress guarantees of Non-blocking algorithms {#termination-safety-forward-progress-guarantees-of-non-blocking-algorithms}

-   wait-free, loсk-free etc. are theoretical properties that consider kind of corner cases.

<!--listend-->

```text
// forward progress gurantees
|<-less gurantee--------------------------------more gurantee->|
lock based algorithms < obstruction-free < lock-free < wait-free
|------blocking-------|-------------- non-blocking ------------|
```


### Wait-free {#wait-free}

-   Guaranteed per-thread progress (strongest guarantee)
-   No computation can ever be blocked by another computation
-   Hard [to implement](https://rethinkdb.com/blog/lock-free-vs-wait-free-concurrency/)


### Lock-free {#lock-free}

-   Guaranteed system-wide progress
-   Some thread can be blocked by other thread but CPU can continue doing other useful work without stalls


### Obstruction-free {#obstruction-free}

-   Thread makes forward progress only if it does not encounter contention from other threads
-   Does not **block** other threads
-   Livelock is possible


## Primitives {#primitives}


### Atomics {#atomics}

-   Atomic operations are ones which manipulate memory in a way that appears indivisible: No thread can observe the operation half-complete.
-   Different primitives allow different levels of forward progress gurantees.
    -   Eg. CAS can't be used to implement `wait-free` but can be used to implement `lock-free`.


#### Read-modify-write (RMW) {#read-modify-write--rmw}

<!--list-separator-->

-  Compare-And-Swap Loops (CAS)

    > It guarantees that: `no other thread wrote to the memory location in between the "compare" and the "swap"`

    -   Its more of an idea of an operation. Different systems implement it differently.

    <!--list-separator-->

    -  How it's actually implemented

        <!--list-separator-->

        -  CPU architectures

            -   `always-succeed`
                -   Some architectures simply lock that memory location (or cache line) during the operation so that other writes are impossible.
            -   `might-fail`
                -   On other architectures (so-called [LL/SC](https://www.wikiwand.com/en/Load-link/store-conditional)), the core doing the CAS may simply monitor the memory location, and if another write occurs at the wrong time, the CAS will not do its write and indicate failure instead.

        <!--list-separator-->

        -  OS/Libraries

            -   In some cases the mutex(in OS/lang library) is probably implemented using a CAS or similar atomic operation
            -   Linux: [Lockless patterns: an introduction to compare-and-swap [LWN.net]​](https://lwn.net/Articles/847973/)
            -   `single-core`
                -   Usually, single-core systems where atomicity is not a concern
                    -   The language's CAS function may be implemented in a simpler and cheaper way without needing such special instructions.
                -   single-core systems still need atomicity with respect to interrupts. `CAS SHOULD BE an uninterruptible` operation and single core CPUs perform virtualized parallelization (context switches)

        <!--list-separator-->

        -  Object stores/other system

            -   These apply the idea of CAS using whatever underlying premitive is available, we just need to ensure the atomicity gurantee that CAS provides
            -   See [Object Store (eg. S3)]({{< relref "20240630172513-object_store_eg_s3.md" >}}) Consistency in object stores can be provided via CAS

    <!--list-separator-->

    -  Resources

        -   See [ABA problem - Wikiwand](https://www.wikiwand.com/en/ABA_problem)

<!--list-separator-->

-  fetch-and-add (FAA)


#### Load and Stores (LAS) {#load-and-stores--las}

-   `load-and-store` vs `compare-and-swap` : [Lockless patterns: an introduction to compare-and-swap [LWN.net]​](https://lwn.net/Articles/847973/)
