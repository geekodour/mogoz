+++
title = "Disk I/O"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Linux]({{< relref "20221101150211-linux.md" >}}), [Systems]({{< relref "20221101150250-systems.md" >}}), [Filesystems]({{< relref "20221101145053-filesystems.md" >}}), [Storage]({{< relref "20221101164723-storage.md" >}})

Thanks to [Alex](https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017) for his amazing blogposts explaining these concepts!

Both memory mapped I/O and standard I/O internally access files `on disk` through `page cache`. We can use the `O_DIRECT` to skip the page cache.


## Standard IO {#standard-io}

It's basically [syscalls]({{< relref "20230330194208-syscalls.md" >}}) combined with userland optimizations. (Eg. `fopen, fwrite, fread, fflush, fclose`). It also involves copying your data from the page cache to the userland buffer cache. So essentially there is 2 cost: `syscalls` and `copying` of data.
 ![](/ox-hugo/20230402013722-disk_i_o-485356102.png)


### Userspace buffering {#userspace-buffering}

-   See `man setbuf`
-   This is not the kernel buffer (`page cache`) (See [Virtual Memory]({{< relref "20221101214011-virtual_memory.md" >}}))


#### Unbuffered {#unbuffered}

-   Information appears on the destination file or terminal as soon as written
-   `stderr` is usually unbuffered


#### Block buffered ðŸŒŸ {#block-buffered}

-   Many characters are saved up and written as a block
-   Usually files are block buffered
-   `fflush(3)` may be used to force the block out early.


#### Line buffered {#line-buffered}

-   Characters are saved up until a newline is output or input is read from any stream attached to a terminal device (typically stdin).
-   `stdout` is usually line buffered


### How disk read happens {#how-disk-read-happens}

-   CPU initiates **disk read**
    -   Sends (`logical block no`, `memory address`, `command`)
    -   Through `bus interface` -&gt; `I/O bridge` -&gt; `I/O bus` -&gt; `disk controller`
-   `Disk controller`
    -   Executes the command
    -   Uses `DMA` to send that data over to memory.
    -   Sends an [Interrupts]({{< relref "20221101173720-interrupts.md" >}}) informing transfer done
-   [Virtual Memory]({{< relref "20221101214011-virtual_memory.md" >}})
    -   Now that stuff is in memory
    -   Kernel will try to caches FS `blocks` in memory into the Page cache.
    -   VM works with `Pages`, which is usually 4096, similar to the size of FS `block` in my case, but it does not have to be like that.


### Blocks v/s Sectors {#blocks-v-s-sectors}

<div class="warning small-text">

> Virtual Memory `pages` &lt;=&gt; Filesystem `blocks` &lt;=&gt; Block Device `sectors`
</div>


#### Filesystem {#filesystem}

-   `Block` is an abstraction of [Filesystems]({{< relref "20221101145053-filesystems.md" >}}) (See [Storage layers]({{< relref "20221101164723-storage.md#storage-layers" >}}))
-   All FS operations can be accessed only in multiple of `Blocks`.
-   `tune2fs` will give you `Block size` for your FS. (Usually `4096`)


#### Block Device {#block-device}

-   [Block device]({{< relref "20230314123832-unix_files.md#block-device" >}}) provides unbuffered access to hardware. Linux uses block device to access disk devices such as [SSDs]({{< relref "20221101213401-memory_hierarchy.md#ssds" >}}) and [HDDs]({{< relref "20221101213401-memory_hierarchy.md#hdds" >}})
-   Smallest addressable unit on a block device is a `sector`. It is not possible to transfer less than one `sector` worth of data.
-   `fdisk -l` will give you the `sector size` of your block device. (Usually `512`)


### Under the hood syscalls {#under-the-hood-syscalls}

-   open, write, read, fsync, sync, close


#### Read {#read}

-   Page Cache is addressed first.
-   If the data is absent, the Page Fault is triggered and contents are paged in.
-   Non-sequential access requires another system call `lseek`.
-   If a `page` gets dirty, `read()` will read from the Page Cache instead of reading from (now outdated) disk.


#### Write {#write}

-   Buffer(userland) contents are first written to Page Cache.
-   Data does not reach the disk right away.
-   Actual hardware write is done when kernel writebacks the `dirty page`.
-   You can also use `fsync`
-   The `writeback` of `dirty page` from Page Cache to disk can be configured via thresholds and ratios.


## Memory mapped IO {#memory-mapped-io}

-   open, mmap, msync, munmap
-   See [mmap]({{< relref "20230405022848-mmap.md" >}}), can tell it to use [Copy on Write]({{< relref "20230405020429-copy_on_write.md" >}}) semantics
-   A memory region in "process address space" is mapped directly to "page cache". No additional userspace buffer cache involved.
    ![](/ox-hugo/20230402013722-disk_i_o-289336833.png)
-   Any dirty page handling is now done by the OS


### How the mapping happens {#how-the-mapping-happens}

-   File is memory mapped
-   Space for the memory mapping is reserved, but not allocated
-   Attempts to access file region, if first read/write, page fault
-   Allocation happens
-   One can also pre-fault using `MAP_POPULATE`


### Improving memory mapped IO {#improving-memory-mapped-io}

-   There's no single way, but using Advice [syscalls]({{< relref "20230330194208-syscalls.md" >}}) can help.


## Async IO (AIO) {#async-io--aio}

Interface allows initiating multiple IO operations &amp; register callbacks


### Pitfalls {#pitfalls}

-   `glibc` has no interface. There's `libio` but people say it sucks.
-   Usually you don't want to be writing code with direct calls to `epoll/poll/select/kqueue` etc. Because not good for portability.
-   It is something of a black art, and has [many pitfalls](https://stackoverflow.com/questions/34572559/asynchronous-io-io-submit-latency-in-ubuntu-linux/46377629#46377629).
-   There are userland libraries such as libenev, [libuv](https://en.wikipedia.org/wiki/Libuv)(used in node.js) etc. which use their own logic to do async io.


### io_uring {#io-uring}

-   `io_uring` tries to learn from the pitfalls and suggests a newer interface
-   Originally designed to target block devices and files but now likes to mingle w network sockets too.
-   <https://kernel.dk/io_uring.pdf>
-   [What is io_uring? â€” Lord of the io_uring documentation](https://unixism.net/loti/what_is_io_uring.html)
-   [How io_uring and eBPF Will Revolutionize Programming in Linux - ScyllaDB](https://www.scylladb.com/2020/05/05/how-io_uring-and-ebpf-will-revolutionize-programming-in-linux/)
-   [io_uring and networking in 2023 Â· axboe/liburing Wiki Â· GitHub](https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023/a6b20fcee88b253eb7dd8240e3c6535c4d32de72)
-   [Getting Hands-on with io_uring using Go](https://developers.mattermost.com/blog/hands-on-iouring-go/)
-   [GitHub - espoal/awesome-iouring: Delightful io_uring packages and resources](https://github.com/espoal/awesome-iouring)


## Vectored IO (Scatter/Gather) {#vectored-io--scatter-gather}

![](/ox-hugo/20230402013722-disk_i_o-497171156.png)
Operates on a vector of buffers and allows reading and writing data to/from disk using multiple buffers per system call.

-   Allows for
    -   Reading smaller chunks
    -   Reducing the amount of system calls
-   Uses
    -   Analytics workloads and/or columnar databases(data stored contiguously)
    -   Processing can be done in parallel in sparse blocks
    -   Eg. Apache Arrow


## Non Blocking IO {#non-blocking-io}

-   Take away: Non-Blocking IO [does not work for regular files](https://www.remlab.net/op/nonblock.shtml).


## IO Schedulers {#io-schedulers}

Typical SSD throughput is greater than 10_000 IOPS, while a typical HDD can handle only about 200 IOPS. There is a queue of requests that have to wait for access to the storage. This is where IO schedulers come in.

-   Arch wiki has great [summary on the algorithms](https://wiki.archlinux.org/title/improving_performance#The_scheduling_algorithms)


### Legacy {#legacy}

-   [Elevator](https://en.wikipedia.org/wiki/Elevator_algorithm) : Order by logical address, not optimal for sequential access
-   [Anticipatory](https://en.wikipedia.org/wiki/Anticipatory_scheduling) : Tries to improve Elevator by waiting for other seq requests
-   [Deadline](https://en.wikipedia.org/wiki/Deadline_scheduler) : Came in to prevent starvation. Bad for overall throughput.
-   [Completely fair queueing](https://en.wikipedia.org/wiki/CFQ) (`cfq`): Allocates timeslice and queue size by process. [cgroups]({{< relref "20230304201630-cgroups.md" >}}) is supported, Good for cloud hosting etc.


### Newer {#newer}

-   [Budget Fair Queueing](https://algo.ing.unimo.it/people/paolo/disk_sched/) (`bfq`): Improves on `cfq`. Has high per operation overhead, so using this on a slow CPU, can slow down the whole thing. Focus on lowest latency rather than highest throughput.
-   mq-deadline: Adaptation of the deadline scheduler to multi-threading. Good for non-rotating media.
-   [Kyber](https://lwn.net/Articles/720675/) : New kid in the block. Token based.


## Other notes {#other-notes}


### Sparse File {#sparse-file}

Sparse files are files stored in a file system where consecutive data blocks consisting of all zero-bytes (null-bytes) are compressed to nothing.

-   Use: Bittorrent, VM images etc.
-   [What are sparse files and how to tell if a file is stored sparsely | Ctrl blog](https://www.ctrl.blog/entry/sparse-files.html) (Best explanation)
-   [Sparse file - Wikipedia](https://en.wikipedia.org/wiki/Sparse_file)
-   [linux - How to view contents of a sparse file? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/521917/how-to-view-contents-of-a-sparse-file)
-   [filesystems - What are functions to manipulate sparse files under Linux? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/366373/what-are-functions-to-manipulate-sparse-files-under-linux)
-   [filesystems - How transparent are sparse files for applications? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/733150/how-transparent-are-sparse-files-for-applications)
-   [filesystems - What is a sparse file and why do we need it? - Stack Overflow](https://stackoverflow.com/questions/43126760/what-is-a-sparse-file-and-why-do-we-need-it)


### Reading large files {#reading-large-files}

-   [What they don't tell you about demand paging in school - offlinemark](https://offlinemark.com/2020/10/14/demand-paging/)


## Resources {#resources}

-   [Learn about different I/O Access Methods and what we chose for ScyllaDB](https://www.scylladb.com/2017/10/05/io-access-methods-scylla/) ðŸŒŸ
-   Others
    -   [memory - Are files opened by processes loaded into RAM? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/367982/are-files-opened-by-processes-loaded-into-ram)
    -   [linux - What happens if you edit a script during execution? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/88487/what-happens-if-you-edit-a-script-during-execution)
    -   [bash - Understanding "IFS= read -r line" - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/209123/understanding-ifs-read-r-line)
    -   [Why is using a shell loop to process text considered bad practice? - Unix &amp; Linux Stack Exchange](https://unix.stackexchange.com/questions/169716/why-is-using-a-shell-loop-to-process-text-considered-bad-practice)
