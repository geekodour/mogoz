+++
title = "Embeddings"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Open Source LLMs]({{< relref "20230719050449-open_source_llms.md" >}}), [NLP (Natural Language Processing)]({{< relref "20231123010516-nlp_natural_language_processing.md" >}}), [Machine Learning]({{< relref "20230408190056-machine_learning.md" >}}), [Modern AI Stack]({{< relref "20230326092427-modern_ai_stack.md" >}}), [Information Retrieval]({{< relref "20231123014416-information_retrieval.md" >}})

Embeddings are related to what we talk about when we talk about "Autoencoders" from [NLP (Natural Language Processing)]({{< relref "20231123010516-nlp_natural_language_processing.md" >}})

-   Multilingual Embedding leaderboard: [MTEB Leaderboard - a Hugging Face Space by mteb](https://huggingface.co/spaces/mteb/leaderboard)


## What {#what}

-   reversing embeddings is probabilistic.


## RAG {#rag}

See [RAG]({{< relref "20241227084628-rag.md" >}})


## VectorDBs / Vector Stores {#vectordbs-vector-stores}

> "Binding generated embeddings to source data, so the vectors automatically update when the data changes is exactly how things should be."

-   [Vector databases are the wrong abstraction | Hacker News](https://news.ycombinator.com/item?id=41985176)

| Vector Store | Type                 | Search Algorithm                     | Performance Characteristics                                   |
|--------------|----------------------|--------------------------------------|---------------------------------------------------------------|
| vectorlite   | SQLite extension     | HNSW (Approximate Nearest Neighbors) | Faster for large vector sets at the cost of some accuracy     |
| sqlite-vec   | SQLite extension     | Brute force                          | More accurate but slower with large vector sets               |
| usearch      | SQLite extension     | Brute force                          | Similar to sqlite-vec, only exposes vector distance functions |
| Qdrant       | Standalone vector DB | Not specified                        | Works well but "heavier" for many applications                |


### sqlite-vec {#sqlite-vec}

> The problem with Parquet is itâ€™s static. Not good for use cases that involve continuous writes and updates. Although I have had good results with DuckDB and Parquet files in object storage. Fast load times.
>
> If you host your own embedding model, then you can transmit numpy float32 compressed arrays as bytes, then decode back into numpy arrays.
>
> Personally I prefer using SQLite with usearch extension. Binary vectors then rerank top 100 with float32. Itâ€™s about 2 ms for ~20k items, which beats LanceDB in my tests. Maybe Lance wins on bigger collections. But for my use case it works great, as each user has their own dedicated SQLite file.

-   [sqlite-vec v0.1.0 Launch Party Recording! - YouTube](https://www.youtube.com/watch?v=WsfSBMzJZVs)
-   <https://news.ycombinator.com/item?id=40244090>:  initial v0.1.0 release will only have linear scans, but I want to support ANN indexes like IVF/HNSW in the future!


### Polars {#polars}

-   [The best way to use text embeddings portably is with Parquet and Polars | Hacker News](https://news.ycombinator.com/item?id=43162995)


### Vector Tile {#vector-tile}

-   <https://www.reddit.com/r/LocalLLaMA/comments/1ekdg3m/introducing_vectorlite_a_fast_and_tunable_vector/>


### [PostgreSQL]({{< relref "20221102123302-postgresql.md" >}}) (pgvector) {#postgresql--20221102123302-postgresql-dot-md----pgvector}

-   [Understanding pgvector's HNSW Index Storage in Postgres | Lantern Blog](https://lantern.dev/blog/pgvector-storage)


### [DuckDB]({{< relref "20231123234702-duckdb.md" >}}) {#duckdb--20231123234702-duckdb-dot-md}

-   [Vector Similarity Search in DuckDB â€“ DuckDB](https://duckdb.org/2024/05/03/vector-similarity-search-vss.html)


## Learning resources {#learning-resources}

-   <https://github.com/erikbern/ann-benchmarks>
-   <https://huggingface.co/hkunlp/instructor-xl> (embeddings) ðŸŒŸ
-   [Don't use cosine similarity carelessly | Hacker News](https://news.ycombinator.com/item?id=42704078)
-   [The secret ingredients of word2vec (2016) | Hacker News](https://news.ycombinator.com/item?id=43075347)
-   [Evaluating Similarity Methods: Speed vs. Precision](https://blog.colivara.com/from-cosine-to-dot-benchmarking-similarity-methods-for-speed-and-precision) ðŸŒŸ
-   [Nomic Blog: Data Maps, Part 2: Embeddings Are For So Much More Than RAG](https://www.nomic.ai/blog/posts/embeddings-are-for-so-much-more-than-rag?s=35)
-   [Understanding pgvector's HNSW Index Storage in Postgres | Lantern Blog](https://lantern.dev/blog/pgvector-storage)
    -   [sqlite]({{< relref "20230702184501-sqlite.md" >}}) vec
-   [How does cosine similarity work? | Hacker News](https://news.ycombinator.com/item?id=41444590)
-   <https://simonwillison.net/2023/Oct/23/embeddings/>
-   [Binary vector embeddings are so cool | Lobsters](https://lobste.rs/s/f6hsm1/binary_vector_embeddings_are_so_cool)
-   [Embeddings are underrated | Lobsters](https://lobste.rs/s/lqbeno/embeddings_are_underrated)
-   [Embeddings are underrated | Hacker News](https://news.ycombinator.com/item?id=42013762)
-   [Bengaluru System Meetup: Understanding sqlite-vec - YouTube](https://www.youtube.com/watch?v=GpTOsTxuLLA)
-   <https://pamacha.observablehq.cloud/spherical-umap/?s=35>
-   [Exploring Hacker News by mapping and analyzing 40 million posts and comments for fun | Wilson Lin](https://blog.wilsonl.in/hackerverse/)
-   Embedding + CRDT (<https://x.com/JungleSilicon/status/1867603691005706515>)
-   [Hacker News Data Map [180MB] | Hacker News](https://news.ycombinator.com/item?id=42035981)


## Selfhosting Embeddings {#selfhosting-embeddings}

See [Deploying ML applications (applied ML)]({{< relref "20241130100028-deploying_ml_applications_applied_ml.md" >}})

Additionally there's also: <https://github.com/michaelfeil/infinity>

| Feature/Aspect        | Text Embeddings Inference    | Ollama                          | vLLM                                 |
|-----------------------|------------------------------|---------------------------------|--------------------------------------|
| Primary Use Case      | Production embedding serving | Local development &amp; testing | LLM inference with embedding support |
| Implementation        | Rust                         | Go                              | Python                               |
| Setup Complexity      | Low                          | Very Low                        | High                                 |
| Resource Usage        | Minimal                      | Moderate                        | High                                 |
| GPU Support           | Yes                          | Yes                             | Yes (Optimized)                      |
| CPU Support           | Yes                          | Yes                             | Limited                              |
| Model Types           | Embedding only               | Both LLM and Embeddings         | Both LLM and Embeddings              |
| Production Ready      | Yes                          | Limited                         | Yes                                  |
| Deployment Type       | Microservice                 | Local/Container                 | Distributed Service                  |
| Customization         | Limited                      | High                            | High                                 |
| Throughput            | Very High (embeddings)       | Moderate                        | High (both)                          |
| Community Support     | Growing                      | Active                          | Very Active                          |
| Architecture Support  | x86, ARM                     | x86, ARM                        | Primarily x86                        |
| Container Support     | Yes                          | Yes                             | Yes                                  |
| Monitoring/Metrics    | Basic                        | Basic                           | Extensive                            |
| Hot-reload Support    | No                           | Yes                             | No                                   |
| Memory Efficiency     | High                         | Moderate                        | Varies (KV-cache focused)            |
| Documentation Quality | Good                         | Excellent                       | Excellent                            |


### Examples {#examples}

-   <https://blog.brunk.io/posts/similarity-search-with-duckdb/>
-   <https://simonwillison.net/2024/May/10/exploring-hacker-news-by-mapping-and-analyzing-40-million-posts/>
-   <https://modal.com/blog/embedding-wikipedia>
-   <https://modal.com/blog/fine-tuning-embeddings>
-   <https://modal.com/docs/examples/text_embeddings_inference>
-   <https://docs.vllm.ai/en/latest/getting_started/examples/openai_embedding_client.html>
