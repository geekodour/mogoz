+++
title = "Virtual Memory"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Computer Memory]({{< relref "20221101203327-computer_memory.md" >}}), [Filesystems]({{< relref "20221101145053-filesystems.md" >}})


## New hierarchy {#new-hierarchy}


### User process {#user-process}


### Programming language memory model {#programming-language-memory-model}


### Kernel {#kernel}


### Filesystem {#filesystem}


### CPU {#cpu}


### MMU {#mmu}


### Memory {#memory}


### Disk {#disk}


## Memory Management {#memory-management}

-   It's not exact science, everything is tradeoff between tradeoff and accuracy.
-   Example tradeoff: If you limit memory it might affect disk I/O because it'll start evicting the page cache and start using swap.


## What a user process sees {#what-a-user-process-sees}


### Virtual address space(VAS) {#virtual-address-space--vas}

The VAS(Virtual Address Space) of a process consist of stack, heap, code, data, arguments etc.

![](/ox-hugo/20221101132431-gc_essentials_udemy-1968463754.png)
The 3 and 1 GB split explanation: [High memory - Wikipedia](https://en.wikipedia.org/wiki/High_memory)

> ```C
> printf("%p", &i);
> ```
>
> This will show the virtual address of `i`, not the physical address. Virtual addresses are the size of a CPU register.

A process is represented by its vitual address space which is a contagious address space from `addr0` to `MAX_SIZE`. When compiling with `gcc`, the `a.out` (the executable) file contains information about how to create the virtual address space.

The virtual addresses(block addresses) consists of two parts, `table index` and the `offset`. The **physical address** is constructed from the `offset` of the virtual address and the page frame.

> Even [when we have 512 physical](https://landley.net/writing/memory-faq.txt) memory on a 32bit processor, the process will believe that it has 4GB of memory. Thanks to memory mapping.


### Tread local storage {#tread-local-storage}

-   [Thread-local storage(TLS)](https://en.wikipedia.org/wiki/Thread-local_storage) : It's just storage specific to the running thread, many threads can have a variable called `a`; `a` is local to each thread. One usage can be multiple threads accumulating information into a global variable with some kind of sync ofc.


## Why Virtual Memory {#why-virtual-memory}

> -   **IA-32/x86_32/x86/i386** : \\(2^{32}\\) ~= 4GB (32 bit address size) [32 bit machines can still support more ram.(PAE)](https://en.wikipedia.org/wiki/Physical_Address_Extension)
> -   **x86_64/amd64** : \\(2^{64}\\) ~= 16EB (48 bit addresses) [Why do x86-64 systems have only a 48 bit virtual address space?](https://stackoverflow.com/questions/6716946/why-do-x86-64-systems-have-only-a-48-bit-virtual-address-space)
>
> The computer will perform faster (the computer has the ability to calculate 2+2+2=6 instead of having to do 2+2=4+2=6 in an example) - Try this out. x86 vs x86_64

Contents of the computer memory can be transferred to secondary storage; a very common way of doing this is through a memory management technique called "virtual memory", other old ways of managing memory were the single contagious model and partition model. As modern computers typically are running multiple tasks, reading and writing directly from/to physical memory is a bad idea.

It can be implemented using:

-   **Segmentation**
-   **Page Table/Paged Virtual Memory**


## Terms/Jargon {#terms-jargon}

-   Process Virtual Memory: **Pages** (Usually 4-64 KB in size) often with the capability to use so called huge pages of 2 MB or 1 GB in size. Sometimes(all zeroes) a page may not be backed by a page frame.
-   RAM, physical memory: **Frames**, it is sometimes also called **Page Frame.** A page frame may back multiple pages. e.g. shared memory or memory-mapped files.
-   **Blocks**: The Virtual memory of a process is split into blocks of equal size, pagesize = blocksize. Sometime `Page` can simply refer to the `Block`
-   **Demand Paging** : The operating system copies a disk page into physical memory only if an attempt is made to access it and that page is not already in memory.


## Paging {#paging}

-   See [Memory Allocation]({{< relref "20221101213324-memory_allocation.md" >}}) and [Memory Design]({{< relref "20221101202144-memory_design.md" >}}) and [Memory Hierarchy]({{< relref "20221101213401-memory_hierarchy.md" >}})
-   Paging is possible due to the MMU which is a hardware thing
-   Paging provides HW level isolation
    -   User processes can only see and modify data which is paged in on their own address space.
    -   System pages are also protected from user processes.

> Run `getconf PAGESIZE` to view the pagesize in your computer in bytes.
>
> ````text
> λ getconf PAGESIZE
> 4096
> ````

The operating system maintains **per process page table** which are stored in the RAM, due to **page tables**, we no longer need to store blocks in contagious manner and everytime the processor tries to access a memory location, it looks into the page table to find the **page frame number.**

| block | page frame |
|-------|------------|
| 1     | 13         |
| 2     | 76         |
| 3     | 55         |

An **access memory location** can be:

-   An instruction
-   Load/Store to some data.

When this memory location access happens for `block 3`, the memory management unit(MMU) in the processor would intercept the access and lookup the **page table** to find the corresponding **page frame** and will generate a **physical address** which will point to `55th page frame` in the RAM.


### Memory Types {#memory-types}

-   From MMU's prespective memory is just pages
-   But there are semantics that are specific to the pages that CPU is not aware of.
-   Anonymous (non file-backed) memory: Not backed by anything. Memory allocated using `malloc` is usually anonymous.


### Locking Pages {#locking-pages}

-   When a page fault occurs and kernel needs to do I/O for paging in
-   Execution time of an instruction skyrockets
-   We can Lock pages for programs that are sensitive to that. See `mlock`


### Page Types {#page-types}

This is not really documented but these are actually usage of pages that I just thought can also be termed "types"

-   Pages that are responsible for holding the code for each process being run on your computer.
-   Pages responsible for caching data and metadata related to files accessed by those programs in order to speed up future access.
-   Pages which are responsible for the memory allocations made inside that code, for example, when new memory that has been allocated with `malloc` is written to, or when using mmap's `MAP_ANONYMOUS` flag. These are "anonymous" pages.

---

-   shared memory, slab memory, kernel stack memory, buffers,
-   Memory is devided into multiple types: anon, (cache, buffers: two sides of the same coin : unified page cache), sockets etc.


### Slab? {#slab}


## MMU Mapping {#mmu-mapping}

-   Now there are even systems which do not have a MMU, The linux memory management system for it is called `nommu`
-   MMU deals in pages
-   Even though, processor's smallest addressable unit may be a byte or word

In order to implement Paged Virtual Memory, there is a chip called Memory Management Unit (MMU). MMU sits between CPU and memory but in practice, it's right there in the CPU chip itself. The MMU maps memory through a [series of tables](https://wiki.osdev.org/Paging), two to be exact. They are the paging directory (PD), and the paging table (PT).

The operating system maintains **per process page table** which are **stored in the RAM** when a process starts to execute. The page table is where the operating system stores its mappings of virtual addresses to physical addresses, with each mapping also known as a **page table entry (PTE)** (So each page table entry us a page????).

The `PTBR` (Page Table Base Register) holds the address to the base address of the **page table**.

> `CR3` register on x86 processors hold the physical base address of page directory (PTBR)

The **translation lookaside buffer (TLB)** is a memory cache in the `MMU`, It stores the recent translations of virtual memory to physical memory and can be called an address-translation cache. The majority of desktop, laptop, and server processors include one or more TLBs in the memory-management hardware.


## Swap {#swap}


### What {#what}

-   We might want to disable swap for certain/main "workloads" but we **still** want it for the whole system.
-   vm.swappiness and writeback throttling WBT(see page cache)
-   Things that swap is good at, you can't get them any other way. Having big memory makes no difference.
-   It is not for emergency memory, to me it is how vm works in linux and all the memory hie. swap is not directly related to RAM, it has a certain usecases that cannot be done without swap.
-   you can run a system without swap but it will not have the benifits that swap has to offer. People think if you don't use swap everything will happen in memory only, but it still has to to flush stuff to disk (filemapped io?) (DOUBT)
-   SWAP is related to the memory types we discussed earlier and not directly related to RAM, and provides a backing store for them(anonymous memory doesn't have a place to go back to so goes to swap).
-   You also cannot reclaim/evict anonymous memory if there is no swap!
    -   Swap allows reclaim on types of memory which otherwise be locked in memory.
    -   We're just going to throw the file cache (thrash the file cache) to make space for it
    -   Worse: We might have to reclaim/evict actual hot page to make space for it.
-   Misconception: Disabling swap will lead prevent disk io in case of memory contention
-   On SSDs, swapping out anonymous pages and reclaiming file pages are essentially equivalent in terms of performance/latency. On older spinning disks, swap reads are slower due to random reads, so a lower vm.swappiness setting makes sense there

Metrics for swap:

-   Swap Activity (swap-ins and swap outs)
-   Amount of swap space used

The kernel's aggressiveness in preemptively swapping-out pages is governed by a kernel parameter called swappiness. It can be set to a number from 0 to 100, where 0 means that more is kept in memory and 100 means that the kernel should try and swap-out as many pages as possible. The default value is 60.


### Good {#good}

-   Gives us time for memory contention to ramp up gradually


### Bad {#bad}

-   Can delay invocation of OOM killer


### Swapfile vs Swap Partitions {#swapfile-vs-swap-partitions}

-   Pros/cons of Swapfile vs Swap partition?
-   No significant advantage of having a partition
-   Might as well use just a swapfile
-   using zswap/zram for swap versus file based swap


## Thrashing {#thrashing}

-   Happens at different levels


## OOM {#oom}

-   Reactive, not proactive, based on reclaim failure
-   Linux does not know when it is out of memory. Only when it tries to reclaim memory and fails for a long time it realizes it's out of memory.
-   Because of this variability in reclaimimnng stuff and because it's not so simple it's hard to predict when we be out of memory
-   How many pages can be freed can only be known via trying to reclaim them
-   Goal is to avoid having to invoke oom killer at all and to avoid memory starvation
-   It is not aware of what it is even killing, it just kills. So if the memory congestion issue needed proccess X to be killed, OOM might just kill Y.
-   One scenario about OOMs, even if there are a lot of cache and buffers available, if the kernel decides that there are important things in these it will not evict them! Therefore you system might go out of memory even if it has stuff in cache and buffer.
-   Because of this, we need a OOM daemon(based on memory pressure) which can kill things before we actually run out of memory. oomd is one example.
    -   context aware decisons
    -   kills when killing is needed
    -   more configurable than kernal oom
    -   oomd, systemdoomd, earlyoom


## Reclaim {#reclaim}

-   Reclaim : Try to free a page. Unload stuff memory. Make space for new stuff.
-   Reclaimable memory is not guaranteed
    -   We need to ask when is it reclaimable, because it's not a binary option
    -   Some page types maybe totally unreclaimable like some kernel structures.
    -   Some page in the cache might be super hot and reclaiming them makes no sense
    -   Sometimes you need to do something else before you can reclaim, eg. flush dirty pages.
-   How?
    -   `kswapd` reclaim : Background kernel thread, proactively tries reclaiming memory
    -   Direct: If `kswapd` was sufficient, we'd never need direct reclaim. Direct reclaim usually blocks application as it tries to free up memory for it.


## Dirty pages {#dirty-pages}

-   Pages in the `page cache` which have been modified and are waiting to be written back to disk.
-   If we want to reclaim a dirty page, we need to flush it to disk first.


## Cache {#cache}

See [VFS]({{< relref "20221101145053-filesystems.md#vfs" >}})


### Buffer cache {#buffer-cache}

-   Sits between the FS and disk
-   Caches disk blocks in memory


### Page cache {#page-cache}

-   Sits between the [VFS]({{< relref "20221101145053-filesystems.md#vfs" >}}) layer and the FS
-   Caches memory pages
-   No need to call into filesystem code at all if the desired page is present already.


### Unified cache {#unified-cache}

-   Ingo Molnar unified both of them in 1999.
-   Now, the `buffer cache` still exists, but its entries point into the `page cache`


## Memory overcommit {#memory-overcommit}

-   I run all my production systems with vm.overcommit_memory = 2: why shouldn't I; or alternatively: why doesn't everyone else do this?
-   `vm.overcommit_memory` is probably the worst sysctl
-   if virtually allocated memory is greater than system memory, then we refuse to overcommit anymore


## Huge Pages {#huge-pages}


## Links {#links}

-   [libc manual memory concepts](https://www.gnu.org/software/libc/manual/html_node/Memory-Concepts.html#Memory-Concepts)
-   [Kerverl Virtual Memory vs User Vertual Memory](https://stackoverflow.com/questions/8708463/difference-between-kernel-virtual-address-and-kernel-logical-address)
-   [Concepts overview — The Linux Kernel documentation](https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html)
-   [The future of the page cache {LWN.net}](https://lwn.net/Articles/712467/)
