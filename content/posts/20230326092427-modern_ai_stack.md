+++
title = "Modern AI Stack"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [Programming Languages]({{< relref "20221101220306-programming_languages.md" >}}), [Machine Learning]({{< relref "20230408190056-machine_learning.md" >}}), [Computer Vision]({{< relref "20240629114811-object_detection.md" >}})

This is to understand what happened in AI post 2020. Also to keep track of things.


## NLP {#nlp}

See [NLP (Natural Language Processing)]({{< relref "20231123010516-nlp_natural_language_processing.md" >}})


## Transformers {#transformers}

![](/ox-hugo/20230326092427-modern_ai_stack-1255652474.png)
![](/ox-hugo/20230326092427-modern_ai_stack-2069610963.png)


### Transformers FAQ {#transformers-faq}


#### zero-shot/one-zero/few-shot learning? {#zero-shot-one-zero-few-shot-learning}

-   Full training: This is not even in the shot spectrum, we train the whole data to get predictions. We can do "shot" kind of things on pre-trained models.
-   few-shot: few more example/runs, we give it few examples etc.
-   one-shot: give one example, it'll be able to do it.
-   zero-shot
    -   We do not want to give any concrete examples at all
    -   But instruct the model in a different way.  (Eg. Prompting)


#### What attention? {#what-attention}

-   In each layer of the network
    -   Encoders taking words from an input sentence, converting them into a representation
    -   Each decoder takes all the encoders’ representation of words and transforms them into words in another language.
-   Decoders getting all the encoders’ output provides a wider context and enables Attention.


### Usage (Modality) {#usage--modality}

-   Text
    -   Text classification
    -   Test generation
    -   Summarization
-   Audio
    -   Audio classification
    -   Automatic speech recognition
-   Vision
    -   Object detection
    -   Image classification
    -   Image segmentation
-   Multi Modal
    -   Visual QA
    -   Document QA
    -   Image captioning


## Diffusion models {#diffusion-models}

-   These are different from transformers in arch, training process, how they infer, usecase etc.
-   See
    -   [⭐ Diffusion Models](https://andrewkchan.dev/posts/diffusion.html)
    -   [What are Diffusion Models? | Lil'Log](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
    -   [Diffusion models are autoencoders – Sander Dieleman](https://sander.ai/2022/01/31/diffusion.html)


### Fineturning diffusion models (Stable Difussion) {#fineturning-diffusion-models--stable-difussion}


#### Dreambooth {#dreambooth}

{{< figure src="/ox-hugo/20230326092427-modern_ai_stack-494918082.png" >}}


#### Textual Inversion {#textual-inversion}

{{< figure src="/ox-hugo/20230326092427-modern_ai_stack-1116443791.png" >}}


#### LoRA {#lora}

{{< figure src="/ox-hugo/20230326092427-modern_ai_stack-743950201.png" >}}


#### Depth-2-Img {#depth-2-img}

{{< figure src="/ox-hugo/20230326092427-modern_ai_stack-318853441.png" >}}


#### ControlNet {#controlnet}

-   It's a training strategy, a way of doing fine tuning
-   It's different from Dreambooth and LoRA in ways that they don't freeze the original model.

![](/ox-hugo/20230326092427-modern_ai_stack-1701974168.png)
![](/ox-hugo/20230326092427-modern_ai_stack-1033145681.png)
![](/ox-hugo/20230326092427-modern_ai_stack-1213872828.png)
![](/ox-hugo/20230326092427-modern_ai_stack-1557053891.png)
![](/ox-hugo/20230326092427-modern_ai_stack-361886987.png)

-   The complimentary external model can be distributed independently or can be baked into one model.
-   The complimentary model is specific to freezed main model so it'll only work with that version so we need to care about compatibility


## TTS {#tts}


### Bark {#bark}

-   <https://github.com/suno-ai/bark>
-   <https://github.com/coqui-ai/TTS>
-   <https://github.com/serp-ai/bark-with-voice-clone>


### tortoise {#tortoise}

-   <https://github.com/neonbjb/tortoise-tts>
-   <https://git.ecker.tech/mrq/ai-voice-cloning>
-   <https://github.com/facebookresearch/fairseq/tree/main/examples/mms>


### Piper {#piper}

-   <https://github.com/rhasspy/piper>


### StyleTTS {#styletts}

-   [StyleTTS2 – open-source Eleven-Labs-quality Text To Speech | Hacker News](https://news.ycombinator.com/item?id=38335255)


## STT {#stt}


### Whisper {#whisper}

-   <https://github.com/guillaumekln/faster-whisper>
