+++
title = "Scraping"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [System Design]({{< relref "20230113141133-system_design.md" >}}),[Archival]({{< relref "20230115032923-archival.md" >}})


## FAQ {#faq}


### Good resources? {#good-resources}

-   <https://github.com/TheWebScrapingClub/webscraping-from-0-to-hero>
-   <https://github.com/lorien/awesome-web-scraping/tree/master> : Awesome list of tools


### Legal? {#legal}

-   [Are website terms of use enforced?](https://blog.apify.com/enforceability-of-terms-of-use/)
-   [Web Scraping for Me, But Not for Thee (Guest Blog Post) - Technology &amp; Marketing Law Blog](https://blog.ericgoldman.org/archives/2023/08/web-scraping-for-me-but-not-for-thee-guest-blog-post.htm)
-   [incolumitas.com ‚Äì So you want to Scrape like the Big Boys? üöÄ](https://incolumitas.com/2021/11/03/so-you-want-to-scrape-like-the-big-boys/)


### Headless non-headless {#headless-non-headless}

-   headless: no gui (eg. webscraping)
-   non-headless: gui, visual rendering (eg. if user needs to keep seeing what the automation does)


### What are diff kinds of scraping bots? {#what-are-diff-kinds-of-scraping-bots}

This list i'll keep updating

-   Sneaker bot: commonly referred to as a ‚Äúshoe bot‚Äù, is a sophisticated software component designed to help individuals quickly purchase limited availability stock.


## Tools {#tools}


### Web Scraping projects {#web-scraping-projects}

| Tool Name   | Description                                                                   | Use Case                                          | Links                                  |
|-------------|-------------------------------------------------------------------------------|---------------------------------------------------|----------------------------------------|
| BrightData  | Developer-focused proxy network and scraping infrastructure                   | Custom scraping solutions                         | [Website](https://brightdata.com)      |
| Diffbot     | AI-powered structured data extraction API                                     | Market research                                   | [Website](https://diffbot.com)         |
| ScrapingBee | Headless browser management service                                           | Browser automation                                | [Website](https://www.scrapingbee.com) |
| Apify       | Cloud-based platform for web scraping and automation                          | Large-scale data extraction, automation workflows | [Website](https://www.apify.com)       |
| Octoparse   | No-code web scraping tool with a user-friendly interface                      | Non-technical data collection                     | [Website](https://www.octoparse.com)   |
| Zyte        | Formerly Scrapinghub; provides Scrapy framework and managed scraping services | Structured data extraction                        | [Website](https://www.zyte.com)        |
| SerpAPI     | API for accessing Google search results programmatically                      | Search engine data collection                     | [Website](https://serpapi.com)         |


### Web Discovery &amp; Mining &amp; Text Processing {#web-discovery-and-mining-and-text-processing}

| Tool Name                                                     | Description                                                          | Use Case                      | Links                                                |
|---------------------------------------------------------------|----------------------------------------------------------------------|-------------------------------|------------------------------------------------------|
| Trafilatura                                                   | Advanced web scraping library with metadata extraction               | Content harvesting            | [GitHub](https://github.com/adbar/trafilatura)       |
| Minet                                                         | Python webmining toolkit with CLI interface                          | Large-scale scraping          | [GitHub](https://github.com/medialab/minet)          |
| postlight/parser                                              | Mercury parser for web content extraction                            | Article extraction            | [GitHub](https://github.com/postlight/parser)        |
| [crawl4ai](https://docs.crawl4ai.com/)                        | Open-Source LLM-Friendly Web Crawler &amp; Scraper                   |                               |                                                      |
| Firecrawl                                                     | Open-source tool for extracting clean, LLM-ready data from websites  | Web scraping for AI apps      | [Website](https://www.firecrawl.dev/)                |
| LLM Scraper                                                   | TypeScript library for structured web scraping using LLMs            | Web data extraction           | [GitHub](https://github.com/mishushakov/llm-scraper) |
| OmniParser                                                    | Computer vision tool for parsing UI screenshots into structured data | GUI automation agents         | [GitHub](https://github.com/microsoft/OmniParser)    |
| [simonw/shot-scraper](https://github.com/simonw/shot-scraper) | Takes pixel-perfect screenshots; can be used for change detection    |                               |                                                      |
| files-to-prompt                                               | Concatenates multiple files into a single prompt for LLM usage       | Prepping text for LLM prompts | [GitHub](https://github.com/simonw/files-to-prompt)  |
| Markitdown                                                    | Markdown-based tool for structuring and organizing content           | Content formatting            | [GitHub](https://github.com/microsoft/markitdown)    |
| defuddle-cli                                                  | CLI tool to simplify and clean up messy datasets or files            | Data cleanup                  | [GitHub](https://github.com/kepano/defuddle-cli)     |
| repomix                                                       | Combines multiple code repositories into a single file               | Codebase unification          | [GitHub](https://github.com/yamadashy/repomix)       |


### Browser automation {#browser-automation}

| Tool Name         | Description                                      | Use Case            | Links                                              |
|-------------------|--------------------------------------------------|---------------------|----------------------------------------------------|
| vimGPT/browserGPT | AI-powered automation tools for editors/browsers | Workflow automation | (Community projects)                               |
| Stagehand         | AI-assisted browser automation framework         | Web testing         | [GitHub](https://github.com/browserbase/stagehand) |


### Change Detection {#change-detection}

| Tool Name          | Description                                                               | Use Case                          | Links                                                    |
|--------------------|---------------------------------------------------------------------------|-----------------------------------|----------------------------------------------------------|
| urlwatch           | Website change monitoring with multiple notification channels             | Content tracking                  | [GitHub](https://github.com/thp/urlwatch)                |
| changedetection.io | Self-hosted visual change detection platform                              | Website monitoring                | [GitHub](https://github.com/dgtlmoon/changedetection.io) |
| Changd             | Open-source web monitoring tool for visual changes, XPath, and API data   | Website change monitoring         | [GitHub](https://github.com/paschmann/changd)            |
| Visualping         | Commercial service for monitoring webpage changes with alerts and reports | Business intelligence, compliance | [Website](https://visualping.io/)                        |


### Post-Processing {#post-processing}

| Tool Name  | Description                    | Use Case         | Links                                              |
|------------|--------------------------------|------------------|----------------------------------------------------|
| strip-tags | HTML tag stripping utility     | Text cleanup     | [GitHub](https://github.com/simonw/strip-tags)     |
| mailparser | Advanced email parsing library | Email processing | [GitHub](https://github.com/nodemailer/mailparser) |


### Social Media Tools {#social-media-tools}

| Tool Name | Description                                        | Use Case               | Links                                                      |
|-----------|----------------------------------------------------|------------------------|------------------------------------------------------------|
| twarc2    | Official Twitter archiving and analysis toolkit    | Social media research  | [Docs](https://twarc-project.readthedocs.io)               |
| snscrape  | Social media scraping toolkit (multiple platforms) | Public data collection | [GitHub](https://github.com/JustAnotherArchivist/snscrape) |
| PMAW      | Pushshift wrapper for Reddit data                  | Reddit analysis        | [GitHub](https://github.com/mattpodolak/pmaw)              |


### Miscellaneous Tools {#miscellaneous-tools}

| Tool Name       | Description                       | Use Case                  | Links                                                   |
|-----------------|-----------------------------------|---------------------------|---------------------------------------------------------|
| browser_cookie3 | Browser cookie extraction library | Authentication automation | [GitHub](https://github.com/borisbabic/browser_cookie3) |
| pdf2htmlEX      | PDF to HTML converter             | Document processing       | [GitHub](https://github.com/pdf2htmlEX/pdf2htmlEX)      |

-   [Surfer: Centralize all your personal data from online platforms | Hacker News](https://news.ycombinator.com/item?id=41325719)
-   <https://github.com/bjesus/pipet>


### Enumeration &amp; Brute-Force {#enumeration-and-brute-force}

| Tool Name | Description                                  | Use Case         | Links                                                                                                      |
|-----------|----------------------------------------------|------------------|------------------------------------------------------------------------------------------------------------|
| Legba     | Advanced network protocol brute-forcing tool | Security testing | [Blog](https://www.evilsocket.net/2023/11/02/Enumerate-Bruteforce-Attack-All-The-Things-Presenting-Legba/) |


## Checklist &amp; Best Practices {#checklist-and-best-practices}


### Checklist {#checklist}

-   [ ] Using something like wappalyzer find out tech used/projection used etc.
-   [ ] Does the website have an API (internal or exposed)?
-   [ ] Does it have some JSON inside the HTML? Eg. site might preload JSON payloads into the initial HTML for hydration.
-   [ ] **Think beyond DOM scraping**
    -   [ ] Does it even need scraping or I can just make an API call
    -   [ ] Does it include a `static` [session]({{< relref "20231102113142-web_sessions.md" >}}) header?
    -   [ ] Does it include a `dynamic` [session]({{< relref "20231102113142-web_sessions.md" >}}) header?
    -   [ ] Does it dump things to the `heap` that we can use objects from it?
-   [ ] If it's DOM based scraping and we using Playwright, can we get around using [codegen](https://playwright.dev/docs/codegen)?
-   [ ] Is the data being served via iframe? in that case we check the source of the frame.
-   [ ] Does it makes certain requests only from mobile app? TODO: How do we catch these?
-   [ ] Is the data being rendered via canvas, so no [DOM]({{< relref "20230614133347-dom.md" >}}) at all? Maybe tools [shot-scraper](https://shot-scraper.datasette.io), [ishan0102/vimGPT](https://github.com/ishan0102/vimGPT), [OpenAdapt](https://github.com/OpenAdaptAI/OpenAdapt),[mayt/BrowserGPT](https://github.com/mayt/BrowserGPT)  can help?


### Best practices {#best-practices}


#### Sites with dynamic sessions {#sites-with-dynamic-sessions}

-   These usually need complex combination of temporary auth token headers which is difficult to do outside the context of the app/expire etc.
-   In these cases, we sort of would need to automate the task of "inspecting the network tab". Application context can help. (See [Page.setRequestInterception()](https://pptr.dev/api/puppeteer.page.setrequestinterception), [Network Events | Playwright](https://playwright.dev/docs/network#network-events))
-   Sometimes they may even be predictable in some way.


#### Sites with data in the runtime Heap {#sites-with-data-in-the-runtime-heap}

-   Eg. find the apollo client instance in memory, use it to get the data. Profit? (See [adriancooney/puppeteer-heap-snapshot](https://github.com/adriancooney/puppeteer-heap-snapshot/tree/master), this will work with playwright as-well because uses the [CDP](https://playwright.dev/docs/api/class-cdpsession)).
-   This can be slow but nice because even if the UI changes frequently, the underlying data-structure to store the data might not etc.


#### DOM based scraping {#dom-based-scraping}

-   We try using playwright codegen if possible
-   Don't use XPath&amp;CSS selectors at all (Except if you don't have choice). You rely on more generic stuff, e.g, "the button that has 'Sign in' on it": `await page.getByRole('button', { name: 'Sign in' }).click();`


### Other ideas {#other-ideas}

{{< figure src="/ox-hugo/20230115032823-scraping-1919827806.png" >}}


## Crawlee Primer {#crawlee-primer}

-   currently supports 3 main crawlers
-   There's request and requestQueue that crawlee offers. These are low level
-   Every crawler has an implicit RequestQueue instance, and you can add requests to it with the crawler.addRequests() method.


### Playwright notes {#playwright-notes}


#### Injecting scripts {#injecting-scripts}

<https://docs.apify.com/academy/puppeteer-playwright/executing-scripts/injecting-code>

```javascript
await page.addInitScript({
  path: path.join(injectionsDir, "dismissDialog.js"),
});

// or
await page.exposeFunction(isShown.name, isShown);
```

I think the benefit of exposeFunction is that we get typesafety for the function, otherwise with `addInitScript` it has to be a proper javascript file(non-ts).


#### Bot detection {#bot-detection}

-   <https://github.com/apify/crawlee-python/issues/684> (Camoufox)


#### Waiting for items to appear {#waiting-for-items-to-appear}

-   `networkidle` is discouraged. See <https://github.com/microsoft/playwright/issues/22897>


## Resources {#resources}


### War stories {#war-stories}

-   So... I built a [Browser Extension]({{< relref "20230819201918-browser_extensions.md" >}}) to grab the data at a speed that is usually under their detection rate. Basically created a distributed scraper and passed it out to as many people in the league as I could.
    -   I found that tampermonkey is often much easier to deal with in most cases and also much quicker to develop for
    -   some sites can block 'self' origin scripts by leaving it out of the [CSP]({{< relref "20230616121539-xss.md#csp" >}}) and only allowing scripts they control served by a CDN


### Others {#others}

-   [Cutting-edge web scraping techniques | Lobsters](https://lobste.rs/s/p0wauf/cutting_edge_web_scraping_techniques)
-   [The most important HTTP headers for scraping | Colly](https://go-colly.org/articles/scraping_related_http_headers/)
-   [Tracking supermarket prices with Playwright | Hacker News](https://news.ycombinator.com/item?id=41173335)
-   [Web Scraping: Bypassing ‚Äú403 Forbidden,‚Äù captchas, and more | Hacker News](https://news.ycombinator.com/item?id=13884357)


## Antibot stuff {#antibot-stuff}


### Antibot Protection {#antibot-protection}

If anti-bot detects your fingerprint or you raise suspicion, you get captcha. Idea is to detect which anti-bot mechanism is at play and then use bypassing techniques when scraping. w some anti-bot tools, you may not even need to use headless browser, maybe just [using rotating proxies will solve it.](https://www.zenrows.com/blog/bypass-akamai)


#### Fingerprinting {#fingerprinting}

See [Anonymity]({{< relref "20230212154657-anonymity.md" >}})

<!--list-separator-->

-  Passive

    This is usually not under your control. You can try changing devices etc.

    -   TCP/IP: IPv4 and IPv6 headers, TCP headers, the dynamics of the TCP handshake, and the contents of application-level payloads. (See [p0f](https://en.wikipedia.org/wiki/P0f))
    -   [TLS]({{< relref "20230210181907-tls.md" >}}): The TLS handshake is not encrypted and can be used [for finger printing](https://blog.squarelemon.com/tls-fingerprinting/).
    -   [HTTP]({{< relref "20230222161545-http.md" >}}) : Special frames in the packet that differ by clients so that we can fingerprint the client etc. [SETTINGS/WINDOW_UPDATE/PRIORITY](https://github.com/TheWebScrapingClub/webscraping-from-0-to-hero/blob/main/Pages/5.Antibot/Akamai_WP_Passive_Fingerprinting.pdf) for [HTTP/2]({{< relref "20230222161545-http.md#http-2" >}})

<!--list-separator-->

-  Active

    In this case, the website tries to run certain tests back on you to check if your fingerprint matches and do whatever action it desires to based on that info

    -   Canvas Fingerprinting: This may try to render something which may [render differently](https://fingerprint.com/blog/canvas-fingerprinting/) in a personal computer vs a vm etc. WebGL Fingerprinting also works similarly.


#### Products offering protection {#products-offering-protection}

-   [Datadome](https://substack.thewebscraping.club/t/datadome)
-   [PerimeterX](https://substack.thewebscraping.club/t/perimeterx)
-   [Kasada](https://substack.thewebscraping.club/t/kasada)
-   Cloudflare
    -   You could also get creative eg. if we can somehow figure out the origin ip somehow(DNS leak, logs, subdomains etc.). But this would only work if the site admin somehow forgot to add [firewalls]({{< relref "20230306125249-firewalls.md" >}}) rules to allow only traffic from cf
-   OSS
    -   [Open-source JavaScript Bot Detection Library](https://fingerprint.com/products/bot-detection/)
    -   [omrilotan/isbot](https://github.com/omrilotan/isbot)


### Antibot solutions {#antibot-solutions}


#### Proxy services {#proxy-services}

> I'll just say that firefox still runs tampermonkey, and that includes firefox mobile, so depending on how often you need a different IP and how much data you're getting, you might be able to do away with the whole idea of proxies and just have a few mobile phones that can be configured as workers that take requests through a tampermonkey script. Or that a laptop tethers to that does the same, or that runs puppeteer itself. It depends on whether a worker needs a new IP every few minutes, hours or days as to whether a real mobile phone works (as some manual interaction is often required to actively change the IP). - kbenson

-   Residential/Mobile
    -   [How IPs For Web Scraping Are Sourced | Scraping Fish](https://scrapingfish.com/how-ips-for-web-scraping-are-sourced)
    -   [Build Your Own Mobile Proxy for Web Scraping | Scraping Fish](https://scrapingfish.com/blog/byo-mobile-proxy-for-web-scraping)
-   4G rotating proxies??


#### Captcha solvers {#captcha-solvers}

-   [2Captcha](https://2captcha.com/?from=3019071)
-   [Abusing Ahrefs backlink checker | Hacker News](https://news.ycombinator.com/item?id=36491313)


#### Obfuscate fingerprint {#obfuscate-fingerprint}

-   May require playing w JS
-   Manage cookies/headers
-   Crack backend APIs and so on.


#### Other configs {#other-configs}

-   There are always specific config that you'll need to trial and error. eg. some sites might not like headless, so you gotta scrape with no-headless or something similar


#### Pre-made solutions {#pre-made-solutions}

-   These usually do the job of Proxy services + Obfuscating fingerprints
-   [Bright data](https://brightdata.com/), Zyte API, Smart Proxy and Oxylabs Web Unlocker
