+++
title = "Scraping"
author = ["Hrishikesh Barman"]
draft = false
+++

tags
: [System Design]({{< relref "20230113141133-system_design.md" >}}),[Archival]({{< relref "20230115032923-archival.md" >}})


## Social Media {#social-media}


### Twitter {#twitter}

-   [twarc2 (en) - twarc](https://twarc-project.readthedocs.io/en/latest/twarc2_en_us/#configure)
-   [snscrape](https://github.com/JustAnotherArchivist/snscrape) : This does more than twitter scraping btw


### Reddit {#reddit}

-   <https://github.com/mattpodolak/pmaw> (uses pushshift)
-   <https://praw.readthedocs.io> (API wrapper)
-   <https://redditsearchtool.com/>


## Random linkdump {#random-linkdump}

-   <https://github.com/nat/natbot>
-   [Abusing Ahrefs Backlink Checker â€“ Trickster Dev](https://www.trickster.dev/post/abusing-ahrefs-backlink-checker/)


## Tools (Eventually move to Primary toolchest) {#tools--eventually-move-to-primary-toolchest}


### General {#general}


#### Playwright {#playwright}

-   Playwright &gt; Puppeter
-   Apparently Playwright [now has some generator](https://playwright.dev/docs/codegen) which works as a recorder and generates PW script.
-   Full browser support
-   [Learn Playwright &amp; Puppeteer | Checkly](https://www.checklyhq.com/learn/headless/)


#### Others {#others}

-   Usually go w Playwright but sometimes might use [Selenium](https://www.browserstack.com/guide/playwright-vs-selenium)


### Golang {#golang}

-   [GitHub - MontFerret/ferret: Declarative web scraping](https://github.com/MontFerret/ferret)
-   [GitHub - gocolly/colly: Elegant Scraper and Crawler Framework for Golang](https://github.com/gocolly/colly)
-   [GitHub - ericchiang/pup: Parsing HTML at the command line](https://github.com/ericchiang/pup)


### Python {#python}


#### Scrapy {#scrapy}

Use it for complex projects that require scraping multiple sites in various ways.


#### BeautifulSoup4 {#beautifulsoup4}

-   Minimal version of Scrapy with only a fraction of the functionality
-   Use it for simple projects where all you need to do is scrape the elements of one web page.
-   Good for really unstructured HTML pages
-   If the page is somewhat structured, Can use underlying parsers(lxml, html5lib, requests-html etc.) directly.
-   <https://github.com/medialab/minet>


#### MechanicalSoup {#mechanicalsoup}

Builds on top of Beautiful Soup and provides functionality to not only parse a web page, but also interact with it like filling forms etc.


### JS {#js}


#### Cheerio {#cheerio}

-   <https://cheerio.js.org/>
-   Use it if you want to quickly extract elements of a web page.


### Cookies {#cookies}

-   <https://github.com/n8henrie/pycookiecheat>
-   <https://github.com/fipso/ccurl.sh>
-   <https://github.com/borisbabic/browser_cookie3>
